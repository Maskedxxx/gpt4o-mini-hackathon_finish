# tests/debug_interview_checklist_formatter.py
"""
–û—Ç–ª–∞–¥–æ—á–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö interview checklist.
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ–∫-–ª–∏—Å—Ç–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –∫ –∏–Ω—Ç–µ—Ä–≤—å—é.
"""

import json
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.llm_interview_checklist.formatter import (
    format_resume_for_interview_prep,
    format_vacancy_for_interview_prep
)

def load_test_data():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–∏."""
    try:
        # –ü—É—Ç–∏ –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º
        resume_path = Path("/Users/mask/Documents/–ü—Ä–æ–µ—Ç—ã_2025/gpt_4_mini_hackaton_final/tests/test_models_res_vac/fetched_resume_6d807532ff0ed6b79f0039ed1f63386d724a62.json")
        vacancy_path = Path("/Users/mask/Documents/–ü—Ä–æ–µ—Ç—ã_2025/gpt_4_mini_hackaton_final/tests/test_models_res_vac/fetched_vacancy_120234346.json")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ
        with open(resume_path, 'r', encoding='utf-8') as f:
            resume_data = json.load(f)
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
        with open(vacancy_path, 'r', encoding='utf-8') as f:
            vacancy_data = json.load(f)
            
        print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        print(f"   ‚Ä¢ –†–µ–∑—é–º–µ: {resume_path.name}")
        print(f"   ‚Ä¢ –í–∞–∫–∞–Ω—Å–∏—è: {vacancy_path.name}")
        
        return resume_data, vacancy_data
        
    except FileNotFoundError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω - {e}")
        return None, None
    except json.JSONDecodeError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON: {e}")
        return None, None
    except Exception as e:
        print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
        return None, None

def test_resume_formatter(resume_data):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä —Ä–µ–∑—é–º–µ –¥–ª—è interview checklist."""
    print("\n" + "="*80)
    print("üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–û–†–ú–ê–¢–¢–ï–†–ê –†–ï–ó–Æ–ú–ï")
    print("="*80)
    
    try:
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ
        formatted_resume = format_resume_for_interview_prep(resume_data)
        
        print("‚úÖ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {len(formatted_resume)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\nüìã –û–¢–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–û–ï –†–ï–ó–Æ–ú–ï:")
        print("-" * 60)
        print(formatted_resume)
        print("-" * 60)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        sections = formatted_resume.split('###')
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´:")
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—Ü–∏–π: {len(sections) - 1}")  # -1 –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å –¥–æ ###
        
        for i, section in enumerate(sections[1:], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—É—é –ø—É—Å—Ç—É—é —á–∞—Å—Ç—å
            section_title = section.split('\n')[0].strip()
            section_content = section.strip()
            content_length = len(section_content)
            print(f"   ‚Ä¢ –°–µ–∫—Ü–∏—è {i}: '{section_title}' ({content_length} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        return formatted_resume
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—é–º–µ: {e}")
        return None

def test_vacancy_formatter(vacancy_data):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–∏ –¥–ª—è interview checklist."""
    print("\n" + "="*80)
    print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –§–û–†–ú–ê–¢–¢–ï–†–ê –í–ê–ö–ê–ù–°–ò–ò")
    print("="*80)
    
    try:
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤–∞–∫–∞–Ω—Å–∏—é
        formatted_vacancy = format_vacancy_for_interview_prep(vacancy_data)
        
        print("‚úÖ –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
        print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞: {len(formatted_vacancy)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        print("\nüéØ –û–¢–§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ù–ê–Ø –í–ê–ö–ê–ù–°–ò–Ø:")
        print("-" * 60)
        print(formatted_vacancy)
        print("-" * 60)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        sections = formatted_vacancy.split('###')
        print(f"\nüìä –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´:")
        print(f"   ‚Ä¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—Ü–∏–π: {len(sections) - 1}")
        
        for i, section in enumerate(sections[1:], 1):
            section_title = section.split('\n')[0].strip()
            section_content = section.strip()
            content_length = len(section_content)
            print(f"   ‚Ä¢ –°–µ–∫—Ü–∏—è {i}: '{section_title}' ({content_length} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        return formatted_vacancy
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
        return None

def analyze_formatting_quality(formatted_resume, formatted_vacancy):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è LLM."""
    print("\n" + "="*80)
    print("üìà –ê–ù–ê–õ–ò–ó –ö–ê–ß–ï–°–¢–í–ê –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("="*80)
    
    try:
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_length = len(formatted_resume) + len(formatted_vacancy)
        print(f"üìä –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"   ‚Ä¢ –û–±—â–∞—è –¥–ª–∏–Ω–∞: {total_length:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ —Ä–µ–∑—é–º–µ: {len(formatted_resume):,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   ‚Ä¢ –î–ª–∏–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏: {len(formatted_vacancy):,} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å
        resume_sections = len(formatted_resume.split('###')) - 1
        vacancy_sections = len(formatted_vacancy.split('###')) - 1
        
        print(f"\nüèóÔ∏è –°–¢–†–£–ö–¢–£–†–ò–†–û–í–ê–ù–ù–û–°–¢–¨:")
        print(f"   ‚Ä¢ –°–µ–∫—Ü–∏–π –≤ —Ä–µ–∑—é–º–µ: {resume_sections}")
        print(f"   ‚Ä¢ –°–µ–∫—Ü–∏–π –≤ –≤–∞–∫–∞–Ω—Å–∏–∏: {vacancy_sections}")
        print(f"   ‚Ä¢ –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–µ–∫—Ü–∏–π: {resume_sections + vacancy_sections}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        combined_text = (formatted_resume + formatted_vacancy).lower()
        keywords = [
            '–æ–ø—ã—Ç', '–Ω–∞–≤—ã–∫–∏', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ', '–ø—Ä–æ–µ–∫—Ç',
            '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è', '–∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏', '—Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è', '–¥–æ–ª–∂–Ω–æ—Å—Ç—å'
        ]
        
        found_keywords = []
        for keyword in keywords:
            if keyword in combined_text:
                count = combined_text.count(keyword)
                found_keywords.append(f"{keyword} ({count})")
        
        print(f"\nüîç –ö–õ–Æ–ß–ï–í–´–ï –°–õ–û–í–ê:")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ: {', '.join(found_keywords)}")
        
        # –û—Ü–µ–Ω–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –¥–ª—è LLM
        if total_length > 500 and resume_sections >= 3 and vacancy_sections >= 3:
            print(f"\n‚úÖ –û–¶–ï–ù–ö–ê: –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM")
            print(f"   ‚Ä¢ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è")
            print(f"   ‚Ä¢ –•–æ—Ä–æ—à–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å")
            print(f"   ‚Ä¢ –°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é")
        else:
            print(f"\n‚ö†Ô∏è –û–¶–ï–ù–ö–ê: –î–∞–Ω–Ω—ã–µ —Ç—Ä–µ–±—É—é—Ç –¥–æ—Ä–∞–±–æ—Ç–∫–∏")
            if total_length <= 500:
                print(f"   ‚Ä¢ –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞")
            if resume_sections < 3:
                print(f"   ‚Ä¢ –ú–∞–ª–æ —Å–µ–∫—Ü–∏–π –≤ —Ä–µ–∑—é–º–µ")
            if vacancy_sections < 3:
                print(f"   ‚Ä¢ –ú–∞–ª–æ —Å–µ–∫—Ü–∏–π –≤ –≤–∞–∫–∞–Ω—Å–∏–∏")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –≤—Å–µ—Ö —Ç–µ—Å—Ç–æ–≤."""
    print("üöÄ –ó–ê–ü–£–°–ö –û–¢–õ–ê–î–ö–ò –§–û–†–ú–ê–¢–¢–ï–†–ê INTERVIEW CHECKLIST")
    print("=" * 80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    resume_data, vacancy_data = load_test_data()
    
    if not resume_data or not vacancy_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
        return
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä—ã
    formatted_resume = test_resume_formatter(resume_data)
    formatted_vacancy = test_vacancy_formatter(vacancy_data)
    
    if formatted_resume and formatted_vacancy:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ
        analyze_formatting_quality(formatted_resume, formatted_vacancy)
        
        print(f"\nüéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –£–°–ü–ï–®–ù–û")
        print(f"   ‚Ä¢ –í—Å–µ —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä—ã —Ä–∞–±–æ—Ç–∞—é—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        print(f"   ‚Ä¢ –î–∞–Ω–Ω—ã–µ –≥–æ—Ç–æ–≤—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ interview checklist")
    else:
        print(f"\n‚ùå –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û –° –û–®–ò–ë–ö–ê–ú–ò")
        print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")

if __name__ == "__main__":
    main()