{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7c435e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем корневую директорию проекта в пути импорта\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Импортируем необходимые модули\n",
    "from src.parsers.resume_extractor import ResumeExtractor\n",
    "from src.parsers.vacancy_extractor import VacancyExtractor\n",
    "from src.llm_gap_analyzer.llm_gap_analyzer import LLMGapAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db9ec865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ПОЛНЫЙ ПРОМПТ ДЛЯ LLM ===\n",
      "\n",
      "        # Задача: Анализ соответствия резюме требованиям вакансии\n",
      "        \n",
      "        Твоя задача - провести детальный анализ соответствия резюме соискателя требованиям вакансии и предоставить конкретные рекомендации по улучшению резюме для повышения шансов на получение данной позиции.\n",
      "        \n",
      "        ## Исходные данные\n",
      "        \n",
      "        ## РЕЗЮМЕ\n",
      "\n",
      "### Желаемая должность\n",
      "LLM Engineer\n",
      "\n",
      "### Описание навыков\n",
      "Я - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.\n",
      "\n",
      "### Ключевые навыки\n",
      "- ChatGPT\n",
      "- AI\n",
      "- prompt\n",
      "- prompt engineering\n",
      "- Python\n",
      "- JSON API\n",
      "- Нейро-сотрудники\n",
      "- Умение работать в команде\n",
      "- Искусственный интеллект\n",
      "- Глубокое обучение\n",
      "- NLP\n",
      "- Машинное обучение\n",
      "- LLM\n",
      "- AI тренер\n",
      "- LangChain\n",
      "- Stable Diffusion\n",
      "- Чат-бот\n",
      "\n",
      "### Опыт работы\n",
      "#### Опыт работы #1: AI engineer\n",
      "Период: 2024-05-01 - None\n",
      "Описание: ***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Сокращение времени создания поздравлений с нескольких часов до нескольких секунд.\n",
      "\n",
      "Рост производительности до 100 поздравлений в день (ранее 5–10).\n",
      "\n",
      "Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\n",
      "=============================\n",
      "\n",
      "***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\n",
      "\n",
      "ЗАДАЧА:\n",
      "Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\n",
      "\n",
      "Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\n",
      "\n",
      "Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\n",
      "\n",
      "Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\n",
      "\n",
      "Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.\n",
      "\n",
      "Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.\n",
      "\n",
      "Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\n",
      "\n",
      "#### Опыт работы #2: AI engineer\n",
      "Период: 2023-08-01 - 2024-05-01\n",
      "Описание: ***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\n",
      "\n",
      "РЕЩЕНИЕ:\n",
      "Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\n",
      "\n",
      "Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\n",
      "\n",
      "Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\n",
      "\n",
      "Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\n",
      "\n",
      "Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\n",
      "\n",
      "Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\n",
      "=======\n",
      "***ПРОЕКТ***: Система автоматического аудита телефонных звонков\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Реализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.\n",
      "\n",
      "Разработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.\n",
      "\n",
      "Применены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Автоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.\n",
      "\n",
      "Ускорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.\n",
      "\n",
      "Улучшение управляемости и прозрачности коммуникаций внутри компании.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Построена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).\n",
      "\n",
      "Весь корпус структурирован в семантические коллекции по тематикам (например, \"регламенты\", \"учебные тексты\", \"терминология\").\n",
      "\n",
      "Внутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.\n",
      "\n",
      "При поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.\n",
      "\n",
      "Выбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая \"галлюцинации\".\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Время получения ответа студентом — менее одной минуты.\n",
      "\n",
      "Существенное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.\n",
      "\n",
      "Повышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)\n",
      "Стек технологий (дополнено):\n",
      "Python, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\n",
      "\n",
      "Методы валидации LLM-ответов (через фреймворк RAGAS)\n",
      "ПРОБЛЕМА:\n",
      "Необходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:\n",
      "\n",
      "    * эталонный ответ (ground truth),\n",
      "\n",
      "    * ссылки на источник (документ, раздел, страница),\n",
      "\n",
      "    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),\n",
      "\n",
      "    * корректное сопоставление извлечённого контекста с ожидаемым ответом.\n",
      "\n",
      "На основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).\n",
      "\n",
      "Как работал RAGAS:\n",
      "Фреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.\n",
      "\n",
      "В пайплайне применялись следующие метрики RAGAS:\n",
      "\n",
      "*Метрика*\t  *Описание*\n",
      "**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».\n",
      "**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.\n",
      "**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.\n",
      "**context_precision** --> Соотношение между использованным и релевантным контекстом.\n",
      "**context_recall** --> Насколько полно покрыт релевантный контекст.\n",
      "**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.\n",
      "Результаты валидации:\n",
      "Валидация дала чёткую картину сильных и слабых сторон модели:\n",
      "\n",
      "Faithfulness > — модель стабильно не «галлюцинирует» (или \"галлюцинирует\").\n",
      "\n",
      "Answer relevancy >  — ответы соответствуют сути вопроса (или нет).\n",
      "\n",
      "Метрики context_precision/recall позволили оптимизировать retriever.\n",
      "\n",
      "Пайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.\n",
      "=======\n",
      "***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).\n",
      "\n",
      "ЗАДАЧА:\n",
      "Повысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Разработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.\n",
      "\n",
      "Создан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.\n",
      "\n",
      "Финальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.\n",
      "\n",
      "Готовый отчёт в формате PDF автоматически отправляется клиенту.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Рост конверсии на 35% при сокращении расходов на колл-центр на 42%.\n",
      "\n",
      "Значительный прирост дополнительной выручки уже в первые 6 месяцев.\n",
      "\n",
      "Высокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.\n",
      "\n",
      "#### Опыт работы #3: Контент-менеджер\n",
      "Период: 2022-07-01 - 2023-07-01\n",
      "Описание: Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\n",
      "\n",
      "#### Опыт работы #4: автор студенческих работ\n",
      "Период: 2022-03-01 - 2023-05-01\n",
      "Описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\n",
      "\n",
      "#### Опыт работы #5: Автор студенческих работ\n",
      "Период: 2022-02-01 - 2023-02-01\n",
      "Описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).\n",
      "\n",
      "### Профессиональные роли\n",
      "- Дата-сайентист\n",
      "- Программист, разработчик\n",
      "- Руководитель проектов\n",
      "\n",
      "### Предпочитаемые типы занятости\n",
      "- Полная занятость\n",
      "- Частичная занятость\n",
      "- Проектная работа\n",
      "\n",
      "### Предпочитаемый график работы\n",
      "- Полный день\n",
      "- Гибкий график\n",
      "- Удаленная работа\n",
      "\n",
      "### Знание языков\n",
      "- Русский: Родной\n",
      "- Английский: A1 — Начальный\n",
      "- Итальянский: A1 — Начальный\n",
      "\n",
      "### Зарплатные ожидания\n",
      "230000 руб.\n",
      "\n",
      "\n",
      "        \n",
      "        ## ВАКАНСИЯ\n",
      "\n",
      "### Описание вакансии\n",
      "Обязанности:  Взаимодействие с заказчиками для сбора и уточнения требований Проектирование и разработка моделей машинного обучения (NLP) Внедрение современных подходов (fine-tuning, prompt-engineering, RAG) Организация процессов валидации моделей Управление командой из 3 датасайнтистов, распределение задач Внедрение методологий MLOps Взаимодействие с Data Architect, Data Analyst, Agile-командами, Data Engineer по вопросам обеспечения потребностей бизнеса в моделях  Требования:   Знание и понимание основных методов машинного обучения, глубокого обучения   Опыт использования LLM (написание промптов, RAG), работы с langchain   Опыт вывода моделей в промышленную эксплуатацию   Знания по терверу и мат. статистике и умение применять их на практике Pytorch  Хорошие аналитические и организационные навыки, коммуникабельность  Условия:  Амбициозные и нестандартные задачи, интересные проекты, возможность внедрять инновационные изменения Возможности внешнего и внутреннего обучения, доступ 24/7 к платформе дистанционного обучения Сбербанка: курсы, лекции, книги, ролики по актуальным направлениям Дружная команда с культурой поддержки и сотрудничества Комфортные условия работы в новом современном офисе в центре города  Ссылка на вакансию в банке вакансий на gsz.gov.⁣by: *Вакансия, планируемая к созданию (перспективная)\n",
      "\n",
      "### Ключевые навыки (требуемые)\n",
      "- PyTorch\n",
      "- NLP\n",
      "- LLM\n",
      "- LangChain\n",
      "\n",
      "### Требуемый опыт работы\n",
      "От 3 до 6 лет\n",
      "\n",
      "### Тип занятости\n",
      "Полная занятость\n",
      "\n",
      "### График работы\n",
      "Полный день\n",
      "\n",
      "\n",
      "        \n",
      "        ## Инструкции по анализу\n",
      "        \n",
      "        Проанализируй следующие разделы:\n",
      "        \n",
      "        1. **Заголовок резюме (title)** - соответствует ли заголовок названию вакансии и ключевым требованиям\n",
      "        2. **Навыки (skills, skill_set)** - присутствуют ли все требуемые навыки из вакансии, какие навыки стоит добавить или выделить\n",
      "        3. **Опыт работы (experience)** - соответствует ли опыт работы требуемому, насколько хорошо описаны релевантные проекты и достижения\n",
      "        4. **Профессиональные роли (professional_roles)** - соответствуют ли указанные профессиональные роли требуемой позиции\n",
      "        \n",
      "        Для каждого раздела определи, что необходимо добавить, изменить или удалить для улучшения соответствия вакансии.\n",
      "        \n",
      "        ## Требования к формату ответа\n",
      "        \n",
      "        Верни ответ строго в формате JSON, соответствующий следующей структуре Pydantic модели ResumeTailoringAnalysis:\n",
      "        \n",
      "        \n",
      "        \n",
      "        ВАЖНО: Для каждого раздела (title, skills, skill_set, experience, professional_roles) должна быть как минимум одна рекомендация. Каждая рекомендация должна содержать не менее 3 конкретных пунктов в списке details. Рекомендации должны быть детальными и практичными.\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Пути к файлам\n",
    "resume_file_path = Path(\"tests/fetched_resume_6d807532ff0ed6b79f0039ed1f63386d724a62.json\")\n",
    "vacancy_file_path = Path(\"tests/fetched_vacancy_120234346.json\")\n",
    "\n",
    "# Загружаем данные\n",
    "with open(resume_file_path, 'r', encoding='utf-8') as f:\n",
    "    resume_data = json.load(f)\n",
    "\n",
    "with open(vacancy_file_path, 'r', encoding='utf-8') as f:\n",
    "    vacancy_data = json.load(f)\n",
    "\n",
    "# Парсим данные\n",
    "resume_parser = ResumeExtractor()\n",
    "vacancy_parser = VacancyExtractor()\n",
    "\n",
    "parsed_resume = resume_parser.extract_resume_info(resume_data)\n",
    "parsed_vacancy = vacancy_parser.extract_vacancy_info(vacancy_data)\n",
    "\n",
    "# Преобразуем Pydantic модели в словари\n",
    "parsed_resume_dict = parsed_resume.model_dump()\n",
    "parsed_vacancy_dict = parsed_vacancy.model_dump()\n",
    "\n",
    "# Создаем экземпляр LLMGapAnalyzer\n",
    "gap_analyzer = LLMGapAnalyzer()\n",
    "\n",
    "# Получаем промпт для gap-анализа (для просмотра)\n",
    "prompt = gap_analyzer._create_gap_analysis_prompt(parsed_resume_dict, parsed_vacancy_dict)\n",
    "\n",
    "# Выводим полный промпт\n",
    "print(\"=== ПОЛНЫЙ ПРОМПТ ДЛЯ LLM ===\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2f1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Часть 2: Вызываем LLM и получаем результаты gap-анализа\n",
    "\n",
    "# Определяем асинхронную функцию для вызова gap_analysis\n",
    "async def run_gap_analysis():\n",
    "    print(\"\\n=== ЗАПУСК GAP-АНАЛИЗА ===\")\n",
    "    print(\"Отправляем запрос к LLM API...\")\n",
    "    \n",
    "    try:\n",
    "        # Вызываем метод gap_analysis для получения результата\n",
    "        result = await gap_analyzer.gap_analysis(parsed_resume_dict, parsed_vacancy_dict)\n",
    "        \n",
    "        if result:\n",
    "            print(\"\\n✅ GAP-анализ успешно выполнен!\")\n",
    "            \n",
    "            # # Выводим количество рекомендаций\n",
    "            # print(f\"Получено {len(result.recommendations)} рекомендаций:\")\n",
    "            \n",
    "            # # Выводим рекомендации в структурированном виде\n",
    "            # for i, rec in enumerate(result.recommendations, 1):\n",
    "            #     print(f\"\\n{i}. Раздел: {rec.section}\")\n",
    "            #     print(f\"   Тип рекомендации: {rec.recommendation_type}\")\n",
    "            #     print(\"    Детали:\")\n",
    "            #     for j, detail in enumerate(rec.details, 1):\n",
    "            #         print(f\"     {j}. {detail}\")\n",
    "            \n",
    "            # Выводим полный JSON результата\n",
    "            print(\"\\n=== ПОЛНЫЙ JSON РЕЗУЛЬТАТА ===\")\n",
    "            print(json.dumps(result.model_dump(), ensure_ascii=False, indent=2))\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            print(\"\\n❌ Ошибка: Не удалось получить результат от LLM\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Ошибка при выполнении gap-анализа: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d04df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ЗАПУСК GAP-АНАЛИЗА ===\n",
      "Отправляем запрос к LLM API...\n",
      "\n",
      "✅ GAP-анализ успешно выполнен!\n",
      "\n",
      "=== ПОЛНЫЙ JSON РЕЗУЛЬТАТА ===\n",
      "{\n",
      "  \"suggested_resume_title\": \"LLM Engineer / AI Engineer с опытом работы с LangChain и RAG\",\n",
      "  \"suggested_skills_description_for_rewriter\": \"Добавьте в описание навыков и раздел ключевых навыков чёткие упоминания PyTorch и опыта промышленного развёртывания моделей, а также выделите навыки управления командой и MLOps. Отразите опыт работы с RAG, fine-tuning и методологиями валидации моделей. В описании добавьте упоминания взаимодействия с Agile-командами и сопутствующими ролями (Data Architect, Data Analyst, Data Engineer).\",\n",
      "  \"suggested_skill_set_for_rewriter\": [\n",
      "    \"PyTorch\",\n",
      "    \"NLP\",\n",
      "    \"LLM\",\n",
      "    \"LangChain\",\n",
      "    \"Prompt Engineering\",\n",
      "    \"RAG\",\n",
      "    \"Fine-tuning моделей\",\n",
      "    \"MLOps\",\n",
      "    \"Валидация моделей\",\n",
      "    \"Управление командой\",\n",
      "    \"Аналитические навыки\",\n",
      "    \"Коммуникабельность\"\n",
      "  ],\n",
      "  \"experience_reports\": [\n",
      "    {\n",
      "      \"experience_identifier\": \"Опыт работы #1: AI engineer\",\n",
      "      \"original_description\": \"***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\\nСТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\\nЗАДАЧА: Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\\nРЕШЕНИЕ: Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\\nРЕЗУЛЬТАТЫ: Сокращение времени создания поздравлений с нескольких часов до нескольких секунд. Рост производительности до 100 поздравлений в день (ранее 5–10). Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\\n=============================\\n***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\\nСТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\\nЗАДАЧА: Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\\nРЕШЕНИЕ: Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\\nИсходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\\nЗапросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\\nМодели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\\nПроект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\\nРЕЗУЛЬТАТЫ: Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем. Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму. Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\",\n",
      "      \"overall_assessment\": \"Опыт демонстрирует глубокое владение технологиями LLM, LangChain, RAG и промышленным развёртыванием в Docker/GPU-средах. Проекты подробно описаны с акцентом на результаты и сложность задач, что хорошо соответствует требованиям вакансии, включая навыки промпт-инжиниринга и семантического роутинга.\",\n",
      "      \"modification_instructions\": [\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": \"Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\",\n",
      "          \"instruction_details\": \"Добавьте короткое описание, как проект связан с NLP и LLM, подчеркните использование Python для разработки. Укажите, если была организована автоматизация с акцентом на качество моделей и интеграцию с бизнес-процессами.\",\n",
      "          \"vacancy_relevance_reason\": \"Вакансия требует опыта с NLP и промышленным применением LLM, поэтому важно показать, что в проекте использовались соответствующие технологии и подходы.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": \"Корпоративный интеллектуальный поиск и автоответчик на основе LLM\",\n",
      "          \"instruction_details\": \"Укажите явный опыт с LangChain, RAG, fine-tuning и использованием Docker/GPU для развёртывания моделей. Выделите аналитические и организационные успехи, а также применение валидации моделей и взаимодействие с командами (Data Architect, Data Engineer).\",\n",
      "          \"vacancy_relevance_reason\": \"Проект демонстрирует релевантные навыки и опыт, соответствующий требованиям вакансии по LLM, промышленному развёртыванию и взаимодействию в команде.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"ADD\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"В начало опыта работы добавьте краткое резюме, отражающее 3+ лет опыта в машиенном обучении с акцентом на LLM и промышленное внедрение. Отметьте опыт руководства и MLOps.\",\n",
      "          \"vacancy_relevance_reason\": \"В вакансии требуется опыт от 3 до 6 лет, управление командой и MLOps, что нужно явно показать в описании опыта.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"experience_identifier\": \"Опыт работы #2: AI engineer\",\n",
      "      \"original_description\": \"***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\\nЗАДАЧА: Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\\nРЕЩЕНИЕ: Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\\nРеализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\\nПроведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\\nИспользованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\\nРЕЗУЛЬТАТЫ: Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\\nДостигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\\nОбеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\",\n",
      "      \"overall_assessment\": \"Опыт хорошо отражает навыки в LLM, Python, работе с гибридным поиском и методах prompt engineering, включая дообучение моделей. Хорошо описаны результаты и экономический эффект, что соответствует требуемой экспертизе.\",\n",
      "      \"modification_instructions\": [\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": \"Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\",\n",
      "          \"instruction_details\": \"Добавьте акцент на опыт промышленного вывода и поддержку моделей в рабочей среде, а также на работу с LangChain и Agile-методами.\",\n",
      "          \"vacancy_relevance_reason\": \"Необходимо показать опыт вывода моделей в промышленную эксплуатацию и взаимодействия с командами, что важно для вакансии.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"ADD\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"В конце описания добавьте информацию о коммуникации с другими ролями (Data Engineer, Data Analyst) и управлении проектом.\",\n",
      "          \"vacancy_relevance_reason\": \"Вакансия требует навыков межкомандного взаимодействия и управления процессами.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": \"Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought)\",\n",
      "          \"instruction_details\": \"Раскройте применение RAG и fine-tuning технологий, укажите участие в организации валидационных процессов моделей.\",\n",
      "          \"vacancy_relevance_reason\": \"Эти навыки важны для соответствия вакансии и отделяют продвинутого специалиста.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"experience_identifier\": \"Опыт работы #3: Контент-менеджер\",\n",
      "      \"original_description\": \"Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\",\n",
      "      \"overall_assessment\": \"Опыт менее релевантен для технической позиции LLM Engineer. Может быть кратко упомянут для иллюстрации коммуникационных навыков, но не нужно делать на нём акцент.\",\n",
      "      \"modification_instructions\": [\n",
      "        {\n",
      "          \"action\": \"DELETE\",\n",
      "          \"target_description_fragment\": \"Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний\",\n",
      "          \"instruction_details\": \"Сократите подробности этого опыта или уберите из основного блока, оставив его лишь упоминанием в профессиональных ролях или дополнительной информации.\",\n",
      "          \"vacancy_relevance_reason\": \"Для LLM Engineer основной фокус должен быть на техническом опыте и навыках, не на контент-менеджменте.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"ADD\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"Если оставлять, выделите в этом опыте навыки организации, коммуникации и работы в команде.\",\n",
      "          \"vacancy_relevance_reason\": \"Коммуникабельность и командная работа требуются для вакансии, и этот опыт может это подтвердить.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"Рассмотрите возможность свести описание к одной-двум строкам и выдвинуть на первый план навыки работы с командами и менеджмента.\",\n",
      "          \"vacancy_relevance_reason\": \"Так описание будет сбалансированным и поможет не перегрузить резюме.\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"experience_identifier\": \"Опыт работы #4: автор студенческих работ\",\n",
      "      \"original_description\": \"Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\",\n",
      "      \"overall_assessment\": \"Опыт не относится к требуемой позиции инженер LLM и не добавляет ценности в контексте вакансии.\",\n",
      "      \"modification_instructions\": [\n",
      "        {\n",
      "          \"action\": \"DELETE\",\n",
      "          \"target_description_fragment\": \"Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов\",\n",
      "          \"instruction_details\": \"Рекомендуется удалить этот опыт из основного резюме, чтобы не отвлекать от релевантного опыта.\",\n",
      "          \"vacancy_relevance_reason\": \"Низкая релевантность к позиции LLM Engineer.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"ADD\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"Если нужно, оставьте упоминание в разделе «Дополнительная информация» или «Прочее».\",\n",
      "          \"vacancy_relevance_reason\": \"Для полноты портфолио, не в основное резюме.\"\n",
      "        },\n",
      "        {\n",
      "          \"action\": \"UPDATE\",\n",
      "          \"target_description_fragment\": null,\n",
      "          \"instruction_details\": \"В случае сохранения свяжите опыт с навыками работы с текстами и аналитики, но минимально.\",\n",
      "          \"vacancy_relevance_reason\": \"Это поможет сгладить переход к более техническим блокам.\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Результат сохранен в файл: gap_analysis_result.json\n"
     ]
    }
   ],
   "source": [
    "# Запускаем асинхронную функцию в Jupyter Notebook\n",
    "result = await run_gap_analysis()  # Для Jupyter нужно использовать top-level await\n",
    "\n",
    "# Если хотите сохранить результат в файл\n",
    "if result:\n",
    "    result_path = Path(\"gap_analysis_result.json\")\n",
    "    with open(result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(result.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "    print(f\"\\nРезультат сохранен в файл: {result_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6fd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e541df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1c8375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semantic_venv)",
   "language": "python",
   "name": "semantic_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
