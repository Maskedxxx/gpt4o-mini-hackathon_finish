
        # ЗАДАЧА: УЛУЧШЕНИЕ РЕЗЮМЕ НА ОСНОВЕ GAP-АНАЛИЗА
        
        Твоя задача - переписать резюме соискателя, учитывая рекомендации из GAP-анализа, чтобы повысить его шансы на получение желаемой позиции.
        
        ## ТЕКУЩЕЕ РЕЗЮМЕ ДЛЯ АНАЛИЗА

### Желаемая должность
LLM Engineer

### Описание навыков (общее)
Я - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.

### Ключевые навыки (список)
- ChatGPT
- AI
- prompt
- prompt engineering
- Python
- JSON API
- Нейро-сотрудники
- Умение работать в команде
- Искусственный интеллект
- Глубокое обучение
- NLP
- Машинное обучение
- LLM
- AI тренер
- LangChain
- Stable Diffusion
- Чат-бот

### Опыт работы
#### Опыт работы (ID: ОПЫТ_ID_1 [Компания не указана - AI engineer])
Период: 2024-05-01 - None
Оригинальное описание: ***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)

СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)

ЗАДАЧА:
Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.

РЕШЕНИЕ:
Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.

РЕЗУЛЬТАТЫ:

Сокращение времени создания поздравлений с нескольких часов до нескольких секунд.

Рост производительности до 100 поздравлений в день (ранее 5–10).

Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.
=============================

***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM

СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU

ЗАДАЧА:
Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.

РЕШЕНИЕ:
Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.

Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.

Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.

Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).

Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.

РЕЗУЛЬТАТЫ:

Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.

Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.

Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.

#### Опыт работы (ID: ОПЫТ_ID_2 [Компания не указана - AI engineer])
Период: 2023-08-01 - 2024-05-01
Оригинальное описание: ***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий

СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.

ЗАДАЧА:
Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.

РЕЩЕНИЕ:
Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.

Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.

Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.

Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.

РЕЗУЛЬТАТЫ:
Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.

Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.

Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.
=======
***ПРОЕКТ***: Система автоматического аудита телефонных звонков

СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)

ЗАДАЧА:
Автоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.

РЕШЕНИЕ:
Реализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.

Разработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.

Применены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.

РЕЗУЛЬТАТЫ:
Автоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.

Ускорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.

Улучшение управляемости и прозрачности коммуникаций внутри компании.
=======
***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы
СТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.

ЗАДАЧА:
Автоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.

РЕШЕНИЕ:

Построена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).

Весь корпус структурирован в семантические коллекции по тематикам (например, "регламенты", "учебные тексты", "терминология").

Внутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.

При поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.

Выбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая "галлюцинации".

РЕЗУЛЬТАТЫ:

Время получения ответа студентом — менее одной минуты.

Существенное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.

Повышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.
=======
***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)
Стек технологий (дополнено):
Python, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF

Методы валидации LLM-ответов (через фреймворк RAGAS)
ПРОБЛЕМА:
Необходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.

РЕШЕНИЕ:

* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:

    * эталонный ответ (ground truth),

    * ссылки на источник (документ, раздел, страница),

    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),

    * корректное сопоставление извлечённого контекста с ожидаемым ответом.

На основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).

Как работал RAGAS:
Фреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.

В пайплайне применялись следующие метрики RAGAS:

*Метрика*	  *Описание*
**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».
**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.
**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.
**context_precision** --> Соотношение между использованным и релевантным контекстом.
**context_recall** --> Насколько полно покрыт релевантный контекст.
**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.
Результаты валидации:
Валидация дала чёткую картину сильных и слабых сторон модели:

Faithfulness > — модель стабильно не «галлюцинирует» (или "галлюцинирует").

Answer relevancy >  — ответы соответствуют сути вопроса (или нет).

Метрики context_precision/recall позволили оптимизировать retriever.

Пайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.
=======
***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций

СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).

ЗАДАЧА:
Повысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.

РЕШЕНИЕ:

Разработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.

Создан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.

Финальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.

Готовый отчёт в формате PDF автоматически отправляется клиенту.

РЕЗУЛЬТАТЫ:

Рост конверсии на 35% при сокращении расходов на колл-центр на 42%.

Значительный прирост дополнительной выручки уже в первые 6 месяцев.

Высокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.

#### Опыт работы (ID: ОПЫТ_ID_3 [Компания не указана - Контент-менеджер])
Период: 2022-07-01 - 2023-07-01
Оригинальное описание: Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.

#### Опыт работы (ID: ОПЫТ_ID_4 [Компания не указана - автор студенческих работ])
Период: 2022-03-01 - 2023-05-01
Оригинальное описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).

#### Опыт работы (ID: ОПЫТ_ID_5 [Компания не указана - Автор студенческих работ])
Период: 2022-02-01 - 2023-02-01
Оригинальное описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).

### Профессиональные роли
- Дата-сайентист
- Программист, разработчик
- Руководитель проектов


        
        ## ЗАДАНИЕ НА АДАПТАЦИЮ РЕЗЮМЕ (ОТЧЕТ ОТ LLM-АНАЛИТИКА)

### 1. Предлагаемый заголовок резюме (Желаемая должность):
LLM Engineer / AI Engineer с опытом работы с LangChain и RAG

### 2. Рекомендации для 'Описания навыков' (общее summary):
Предлагаемая основа для переписывания:
Добавьте в описание навыков и раздел ключевых навыков чёткие упоминания PyTorch и опыта промышленного развёртывания моделей, а также выделите навыки управления командой и MLOps. Отразите опыт работы с RAG, fine-tuning и методологиями валидации моделей. В описании добавьте упоминания взаимодействия с Agile-командами и сопутствующими ролями (Data Architect, Data Analyst, Data Engineer).

### 3. Рекомендуемый 'Ключевой набор навыков' (список):
- PyTorch
- NLP
- LLM
- LangChain
- Prompt Engineering
- RAG
- Fine-tuning моделей
- MLOps
- Валидация моделей
- Управление командой
- Аналитические навыки
- Коммуникабельность

### 4. Инструкции по адаптации опыта работы:

#### 4.1 Для опыта (ID: Опыт работы #1: AI engineer)
**Оригинальное описание (для контекста LLM-копирайтера):**
***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)
СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)
ЗАДАЧА: Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.
РЕШЕНИЕ: Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.
РЕЗУЛЬТАТЫ: Сокращение времени создания поздравлений с нескольких часов до нескольких секунд. Рост производительности до 100 поздравлений в день (ранее 5–10). Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.
=============================
***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM
СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU
ЗАДАЧА: Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.
РЕШЕНИЕ: Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.
Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.
Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.
Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).
Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.
РЕЗУЛЬТАТЫ: Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем. Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму. Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.

**Общая оценка и стратегия адаптации от LLM-аналитика:**
Опыт демонстрирует глубокое владение технологиями LLM, LangChain, RAG и промышленным развёртыванием в Docker/GPU-средах. Проекты подробно описаны с акцентом на результаты и сложность задач, что хорошо соответствует требованиям вакансии, включая навыки промпт-инжиниринга и семантического роутинга.

**Конкретные инструкции по изменению от LLM-аналитика:**
  Инструкция #1:
    Действие: UPDATE
    Целевой фрагмент (из оригинала): "Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)"
    Детали инструкции: Добавьте короткое описание, как проект связан с NLP и LLM, подчеркните использование Python для разработки. Укажите, если была организована автоматизация с акцентом на качество моделей и интеграцию с бизнес-процессами.
    Обоснование (релевантность вакансии): Вакансия требует опыта с NLP и промышленным применением LLM, поэтому важно показать, что в проекте использовались соответствующие технологии и подходы.

  Инструкция #2:
    Действие: UPDATE
    Целевой фрагмент (из оригинала): "Корпоративный интеллектуальный поиск и автоответчик на основе LLM"
    Детали инструкции: Укажите явный опыт с LangChain, RAG, fine-tuning и использованием Docker/GPU для развёртывания моделей. Выделите аналитические и организационные успехи, а также применение валидации моделей и взаимодействие с командами (Data Architect, Data Engineer).
    Обоснование (релевантность вакансии): Проект демонстрирует релевантные навыки и опыт, соответствующий требованиям вакансии по LLM, промышленному развёртыванию и взаимодействию в команде.

  Инструкция #3:
    Действие: ADD
    Детали инструкции: В начало опыта работы добавьте краткое резюме, отражающее 3+ лет опыта в машиенном обучении с акцентом на LLM и промышленное внедрение. Отметьте опыт руководства и MLOps.
    Обоснование (релевантность вакансии): В вакансии требуется опыт от 3 до 6 лет, управление командой и MLOps, что нужно явно показать в описании опыта.


#### 4.2 Для опыта (ID: Опыт работы #2: AI engineer)
**Оригинальное описание (для контекста LLM-копирайтера):**
***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий
СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.
ЗАДАЧА: Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.
РЕЩЕНИЕ: Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.
Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.
Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.
Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.
РЕЗУЛЬТАТЫ: Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.
Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.
Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.

**Общая оценка и стратегия адаптации от LLM-аналитика:**
Опыт хорошо отражает навыки в LLM, Python, работе с гибридным поиском и методах prompt engineering, включая дообучение моделей. Хорошо описаны результаты и экономический эффект, что соответствует требуемой экспертизе.

**Конкретные инструкции по изменению от LLM-аналитика:**
  Инструкция #1:
    Действие: UPDATE
    Целевой фрагмент (из оригинала): "Чат-боты-кураторы на базе LLM для автоматизации проверки заданий"
    Детали инструкции: Добавьте акцент на опыт промышленного вывода и поддержку моделей в рабочей среде, а также на работу с LangChain и Agile-методами.
    Обоснование (релевантность вакансии): Необходимо показать опыт вывода моделей в промышленную эксплуатацию и взаимодействия с командами, что важно для вакансии.

  Инструкция #2:
    Действие: ADD
    Детали инструкции: В конце описания добавьте информацию о коммуникации с другими ролями (Data Engineer, Data Analyst) и управлении проектом.
    Обоснование (релевантность вакансии): Вакансия требует навыков межкомандного взаимодействия и управления процессами.

  Инструкция #3:
    Действие: UPDATE
    Целевой фрагмент (из оригинала): "Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought)"
    Детали инструкции: Раскройте применение RAG и fine-tuning технологий, укажите участие в организации валидационных процессов моделей.
    Обоснование (релевантность вакансии): Эти навыки важны для соответствия вакансии и отделяют продвинутого специалиста.


#### 4.3 Для опыта (ID: Опыт работы #3: Контент-менеджер)
**Оригинальное описание (для контекста LLM-копирайтера):**
Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.

**Общая оценка и стратегия адаптации от LLM-аналитика:**
Опыт менее релевантен для технической позиции LLM Engineer. Может быть кратко упомянут для иллюстрации коммуникационных навыков, но не нужно делать на нём акцент.

**Конкретные инструкции по изменению от LLM-аналитика:**
  Инструкция #1:
    Действие: DELETE
    Целевой фрагмент (из оригинала): "Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний"
    Детали инструкции: Сократите подробности этого опыта или уберите из основного блока, оставив его лишь упоминанием в профессиональных ролях или дополнительной информации.
    Обоснование (релевантность вакансии): Для LLM Engineer основной фокус должен быть на техническом опыте и навыках, не на контент-менеджменте.

  Инструкция #2:
    Действие: ADD
    Детали инструкции: Если оставлять, выделите в этом опыте навыки организации, коммуникации и работы в команде.
    Обоснование (релевантность вакансии): Коммуникабельность и командная работа требуются для вакансии, и этот опыт может это подтвердить.

  Инструкция #3:
    Действие: UPDATE
    Детали инструкции: Рассмотрите возможность свести описание к одной-двум строкам и выдвинуть на первый план навыки работы с командами и менеджмента.
    Обоснование (релевантность вакансии): Так описание будет сбалансированным и поможет не перегрузить резюме.


#### 4.4 Для опыта (ID: Опыт работы #4: автор студенческих работ)
**Оригинальное описание (для контекста LLM-копирайтера):**
Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).

**Общая оценка и стратегия адаптации от LLM-аналитика:**
Опыт не относится к требуемой позиции инженер LLM и не добавляет ценности в контексте вакансии.

**Конкретные инструкции по изменению от LLM-аналитика:**
  Инструкция #1:
    Действие: DELETE
    Целевой фрагмент (из оригинала): "Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов"
    Детали инструкции: Рекомендуется удалить этот опыт из основного резюме, чтобы не отвлекать от релевантного опыта.
    Обоснование (релевантность вакансии): Низкая релевантность к позиции LLM Engineer.

  Инструкция #2:
    Действие: ADD
    Детали инструкции: Если нужно, оставьте упоминание в разделе «Дополнительная информация» или «Прочее».
    Обоснование (релевантность вакансии): Для полноты портфолио, не в основное резюме.

  Инструкция #3:
    Действие: UPDATE
    Детали инструкции: В случае сохранения свяжите опыт с навыками работы с текстами и аналитики, но минимально.
    Обоснование (релевантность вакансии): Это поможет сгладить переход к более техническим блокам.


        
        ## ИНСТРУКЦИИ ПО УЛУЧШЕНИЮ
        
        1. Переработай каждый раздел резюме согласно рекомендациям выше
        2. Сохрани структуру и количество элементов опыта работы - их должно быть столько же, сколько в исходном резюме
        3. Используй профессиональный деловой стиль в описаниях
        4. Сфокусируйся на конкретных достижениях и релевантном опыте
        5. Используй ключевые слова из рекомендаций
        
        ## ФОРМАТ ОТВЕТА
        
        Верни ответ строго в формате JSON, соответствующий структуре Pydantic модели ResumeUpdate:
        
        ```json
        {
            "title": "Обновленная должность",
            "skills": "Обновленное описание навыков...",
            "skill_set": ["Навык 1", "Навык 2", ...],
            "experience": [
                {
                    "position": "Должность 1",
                    "description": "Обновленное описание опыта работы..."
                },
                ...
            ],
            "professional_roles": [
                {
                    "name": "Название профессиональной роли"
                },
                ...
            ]
        }
        ```
        
        ВАЖНО: Раздел "experience" должен содержать ровно 5 объектов - столько же, сколько в исходном резюме.
        