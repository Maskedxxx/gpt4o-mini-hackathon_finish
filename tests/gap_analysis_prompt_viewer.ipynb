{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf9247db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем корневую директорию проекта в пути импорта\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Импортируем необходимые модули\n",
    "from src.parsers.resume_extractor import ResumeExtractor\n",
    "from src.parsers.vacancy_extractor import VacancyExtractor\n",
    "from src.llm_gap_analyzer.llm_gap_analyzer import LLMGapAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb614082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к файлам\n",
    "resume_file_path = Path(\"tests/fetched_resume_6d807532ff0ed6b79f0039ed1f63386d724a62.json\")\n",
    "vacancy_file_path = Path(\"tests/fetched_vacancy_120234346.json\")\n",
    "\n",
    "# Загружаем данные\n",
    "with open(resume_file_path, 'r', encoding='utf-8') as f:\n",
    "    resume_data = json.load(f)\n",
    "\n",
    "with open(vacancy_file_path, 'r', encoding='utf-8') as f:\n",
    "    vacancy_data = json.load(f)\n",
    "\n",
    "# Парсим данные\n",
    "resume_parser = ResumeExtractor()\n",
    "vacancy_parser = VacancyExtractor()\n",
    "\n",
    "parsed_resume = resume_parser.extract_resume_info(resume_data)\n",
    "parsed_vacancy = vacancy_parser.extract_vacancy_info(vacancy_data)\n",
    "\n",
    "# Преобразуем Pydantic модели в словари\n",
    "parsed_resume_dict = parsed_resume.model_dump()\n",
    "parsed_vacancy_dict = parsed_vacancy.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec0bef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ПОЛНЫЙ ПРОМПТ ДЛЯ LLM ===\n",
      "\n",
      "        # Задача: Анализ соответствия резюме требованиям вакансии\n",
      "        \n",
      "        Твоя задача - провести детальный анализ соответствия резюме соискателя требованиям вакансии и предоставить конкретные рекомендации по улучшению резюме для повышения шансов на получение данной позиции.\n",
      "        \n",
      "        ## Исходные данные\n",
      "        \n",
      "        ## РЕЗЮМЕ\n",
      "\n",
      "### Желаемая должность\n",
      "LLM Engineer\n",
      "\n",
      "### Описание навыков\n",
      "Я - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.\n",
      "\n",
      "### Ключевые навыки\n",
      "- ChatGPT\n",
      "- AI\n",
      "- prompt\n",
      "- prompt engineering\n",
      "- Python\n",
      "- JSON API\n",
      "- Нейро-сотрудники\n",
      "- Умение работать в команде\n",
      "- Искусственный интеллект\n",
      "- Глубокое обучение\n",
      "- NLP\n",
      "- Машинное обучение\n",
      "- LLM\n",
      "- AI тренер\n",
      "- LangChain\n",
      "- Stable Diffusion\n",
      "- Чат-бот\n",
      "\n",
      "### Опыт работы\n",
      "#### Опыт работы #1: AI engineer\n",
      "Период: 2024-05-01 - None\n",
      "Описание: ***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Сокращение времени создания поздравлений с нескольких часов до нескольких секунд.\n",
      "\n",
      "Рост производительности до 100 поздравлений в день (ранее 5–10).\n",
      "\n",
      "Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\n",
      "=============================\n",
      "\n",
      "***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\n",
      "\n",
      "ЗАДАЧА:\n",
      "Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\n",
      "\n",
      "Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\n",
      "\n",
      "Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\n",
      "\n",
      "Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\n",
      "\n",
      "Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.\n",
      "\n",
      "Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.\n",
      "\n",
      "Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\n",
      "\n",
      "#### Опыт работы #2: AI engineer\n",
      "Период: 2023-08-01 - 2024-05-01\n",
      "Описание: ***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\n",
      "\n",
      "РЕЩЕНИЕ:\n",
      "Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\n",
      "\n",
      "Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\n",
      "\n",
      "Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\n",
      "\n",
      "Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\n",
      "\n",
      "Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\n",
      "\n",
      "Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\n",
      "=======\n",
      "***ПРОЕКТ***: Система автоматического аудита телефонных звонков\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Реализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.\n",
      "\n",
      "Разработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.\n",
      "\n",
      "Применены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Автоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.\n",
      "\n",
      "Ускорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.\n",
      "\n",
      "Улучшение управляемости и прозрачности коммуникаций внутри компании.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Построена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).\n",
      "\n",
      "Весь корпус структурирован в семантические коллекции по тематикам (например, \"регламенты\", \"учебные тексты\", \"терминология\").\n",
      "\n",
      "Внутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.\n",
      "\n",
      "При поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.\n",
      "\n",
      "Выбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая \"галлюцинации\".\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Время получения ответа студентом — менее одной минуты.\n",
      "\n",
      "Существенное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.\n",
      "\n",
      "Повышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)\n",
      "Стек технологий (дополнено):\n",
      "Python, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\n",
      "\n",
      "Методы валидации LLM-ответов (через фреймворк RAGAS)\n",
      "ПРОБЛЕМА:\n",
      "Необходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:\n",
      "\n",
      "    * эталонный ответ (ground truth),\n",
      "\n",
      "    * ссылки на источник (документ, раздел, страница),\n",
      "\n",
      "    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),\n",
      "\n",
      "    * корректное сопоставление извлечённого контекста с ожидаемым ответом.\n",
      "\n",
      "На основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).\n",
      "\n",
      "Как работал RAGAS:\n",
      "Фреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.\n",
      "\n",
      "В пайплайне применялись следующие метрики RAGAS:\n",
      "\n",
      "*Метрика*\t  *Описание*\n",
      "**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».\n",
      "**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.\n",
      "**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.\n",
      "**context_precision** --> Соотношение между использованным и релевантным контекстом.\n",
      "**context_recall** --> Насколько полно покрыт релевантный контекст.\n",
      "**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.\n",
      "Результаты валидации:\n",
      "Валидация дала чёткую картину сильных и слабых сторон модели:\n",
      "\n",
      "Faithfulness > — модель стабильно не «галлюцинирует» (или \"галлюцинирует\").\n",
      "\n",
      "Answer relevancy >  — ответы соответствуют сути вопроса (или нет).\n",
      "\n",
      "Метрики context_precision/recall позволили оптимизировать retriever.\n",
      "\n",
      "Пайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.\n",
      "=======\n",
      "***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).\n",
      "\n",
      "ЗАДАЧА:\n",
      "Повысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Разработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.\n",
      "\n",
      "Создан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.\n",
      "\n",
      "Финальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.\n",
      "\n",
      "Готовый отчёт в формате PDF автоматически отправляется клиенту.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Рост конверсии на 35% при сокращении расходов на колл-центр на 42%.\n",
      "\n",
      "Значительный прирост дополнительной выручки уже в первые 6 месяцев.\n",
      "\n",
      "Высокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.\n",
      "\n",
      "#### Опыт работы #3: Контент-менеджер\n",
      "Период: 2022-07-01 - 2023-07-01\n",
      "Описание: Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\n",
      "\n",
      "#### Опыт работы #4: автор студенческих работ\n",
      "Период: 2022-03-01 - 2023-05-01\n",
      "Описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\n",
      "\n",
      "#### Опыт работы #5: Автор студенческих работ\n",
      "Период: 2022-02-01 - 2023-02-01\n",
      "Описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).\n",
      "\n",
      "### Профессиональные роли\n",
      "- Дата-сайентист\n",
      "- Программист, разработчик\n",
      "- Руководитель проектов\n",
      "\n",
      "### Предпочитаемые типы занятости\n",
      "- Полная занятость\n",
      "- Частичная занятость\n",
      "- Проектная работа\n",
      "\n",
      "### Предпочитаемый график работы\n",
      "- Полный день\n",
      "- Гибкий график\n",
      "- Удаленная работа\n",
      "\n",
      "### Знание языков\n",
      "- Русский: Родной\n",
      "- Английский: A1 — Начальный\n",
      "- Итальянский: A1 — Начальный\n",
      "\n",
      "### Зарплатные ожидания\n",
      "230000 руб.\n",
      "\n",
      "\n",
      "        \n",
      "        ## ВАКАНСИЯ\n",
      "\n",
      "### Описание вакансии\n",
      "Обязанности:  Взаимодействие с заказчиками для сбора и уточнения требований Проектирование и разработка моделей машинного обучения (NLP) Внедрение современных подходов (fine-tuning, prompt-engineering, RAG) Организация процессов валидации моделей Управление командой из 3 датасайнтистов, распределение задач Внедрение методологий MLOps Взаимодействие с Data Architect, Data Analyst, Agile-командами, Data Engineer по вопросам обеспечения потребностей бизнеса в моделях  Требования:   Знание и понимание основных методов машинного обучения, глубокого обучения   Опыт использования LLM (написание промптов, RAG), работы с langchain   Опыт вывода моделей в промышленную эксплуатацию   Знания по терверу и мат. статистике и умение применять их на практике Pytorch  Хорошие аналитические и организационные навыки, коммуникабельность  Условия:  Амбициозные и нестандартные задачи, интересные проекты, возможность внедрять инновационные изменения Возможности внешнего и внутреннего обучения, доступ 24/7 к платформе дистанционного обучения Сбербанка: курсы, лекции, книги, ролики по актуальным направлениям Дружная команда с культурой поддержки и сотрудничества Комфортные условия работы в новом современном офисе в центре города  Ссылка на вакансию в банке вакансий на gsz.gov.⁣by: *Вакансия, планируемая к созданию (перспективная)\n",
      "\n",
      "### Ключевые навыки (требуемые)\n",
      "- PyTorch\n",
      "- NLP\n",
      "- LLM\n",
      "- LangChain\n",
      "\n",
      "### Требуемый опыт работы\n",
      "От 3 до 6 лет\n",
      "\n",
      "### Тип занятости\n",
      "Полная занятость\n",
      "\n",
      "### График работы\n",
      "Полный день\n",
      "\n",
      "\n",
      "        \n",
      "        ## Инструкции по анализу\n",
      "        \n",
      "        Проанализируй следующие разделы:\n",
      "        \n",
      "        1. **Заголовок резюме (title)** - соответствует ли заголовок названию вакансии и ключевым требованиям\n",
      "        2. **Навыки (skills, skill_set)** - присутствуют ли все требуемые навыки из вакансии, какие навыки стоит добавить или выделить\n",
      "        3. **Опыт работы (experience)** - соответствует ли опыт работы требуемому, насколько хорошо описаны релевантные проекты и достижения\n",
      "        4. **Профессиональные роли (professional_roles)** - соответствуют ли указанные профессиональные роли требуемой позиции\n",
      "        \n",
      "        Для каждого раздела определи, что необходимо добавить, изменить или удалить для улучшения соответствия вакансии.\n",
      "        \n",
      "        ## Требования к формату ответа\n",
      "        \n",
      "        Верни ответ строго в формате JSON, соответствующий следующей структуре Pydantic модели ResumeGapAnalysis:\n",
      "        \n",
      "        ```\n",
      "        {\n",
      "            \"recommendations\": [\n",
      "                {\n",
      "                    \"section\": \"title\",\n",
      "                    \"recommendation_type\": \"update\",\n",
      "                    \"details\": [\"Изменить заголовок на...\", \"Добавить ключевые слова...\", \"Сделать акцент на...\"]\n",
      "                },\n",
      "                {\n",
      "                    \"section\": \"skills\",\n",
      "                    \"recommendation_type\": \"add\",\n",
      "                    \"details\": [\"Добавить навык X...\", \"Подчеркнуть знание Y...\"]\n",
      "                },\n",
      "                // Другие рекомендации по всем разделам\n",
      "            ]\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        ВАЖНО: Для каждого раздела (title, skills, skill_set, experience, professional_roles) должна быть как минимум одна рекомендация. Каждая рекомендация должна содержать не менее 3 конкретных пунктов в списке details. Рекомендации должны быть детальными и практичными.\n",
      "        \n",
      "\n",
      "\n",
      "=== ПОЛНАЯ СТРУКТУРА СООБЩЕНИЙ ДЛЯ API ===\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"Ты — эксперт по рекрутингу и HR с глубоким пониманием IT-индустрии. Твоя специализация — анализ соответствия резюме требованиям вакансий и предоставление конкретных рекомендаций по улучшению. Всегда отвечай строго в формате JSON согласно указанной структуре ResumeGapAnalysis. Рекомендации должны быть конкретными, практичными и детальными, чтобы соискатель мог сразу применить их для улучшения резюме.\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"\\n        # Задача: Анализ соответствия резюме требованиям вакансии\\n        \\n        Твоя задача - провести детальный анализ соответствия резюме соискателя требованиям вакансии и предоставить конкретные рекомендации по улучшению резюме для повышения шансов на получение данной позиции.\\n        \\n        ## Исходные данные\\n        \\n        ## РЕЗЮМЕ\\n\\n### Желаемая должность\\nLLM Engineer\\n\\n### Описание навыков\\nЯ - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.\\n\\n### Ключевые навыки\\n- ChatGPT\\n- AI\\n- prompt\\n- prompt engineering\\n- Python\\n- JSON API\\n- Нейро-сотрудники\\n- Умение работать в команде\\n- Искусственный интеллект\\n- Глубокое обучение\\n- NLP\\n- Машинное обучение\\n- LLM\\n- AI тренер\\n- LangChain\\n- Stable Diffusion\\n- Чат-бот\\n\\n### Опыт работы\\n#### Опыт работы #1: AI engineer\\nПериод: 2024-05-01 - None\\nОписание: ***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\\n\\nСТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\\n\\nЗАДАЧА:\\nАвтоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\\n\\nРЕШЕНИЕ:\\nРазработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\\n\\nРЕЗУЛЬТАТЫ:\\n\\nСокращение времени создания поздравлений с нескольких часов до нескольких секунд.\\n\\nРост производительности до 100 поздравлений в день (ранее 5–10).\\n\\nПовышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\\n=============================\\n\\n***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\\n\\nСТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\\n\\nЗАДАЧА:\\nСоздать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\\n\\nРЕШЕНИЕ:\\nРазработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\\n\\nИсходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\\n\\nЗапросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\\n\\nМодели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\\n\\nПроект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\\n\\nРЕЗУЛЬТАТЫ:\\n\\nПовышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.\\n\\nСнижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.\\n\\nРешение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\\n\\n#### Опыт работы #2: AI engineer\\nПериод: 2023-08-01 - 2024-05-01\\nОписание: ***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\\n\\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\\n\\nЗАДАЧА:\\nАвтоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\\n\\nРЕЩЕНИЕ:\\nРазработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\\n\\nРеализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\\n\\nПроведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\\n\\nИспользованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\\n\\nРЕЗУЛЬТАТЫ:\\nСокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\\n\\nДостигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\\n\\nОбеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\\n=======\\n***ПРОЕКТ***: Система автоматического аудита телефонных звонков\\n\\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)\\n\\nЗАДАЧА:\\nАвтоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.\\n\\nРЕШЕНИЕ:\\nРеализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.\\n\\nРазработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.\\n\\nПрименены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.\\n\\nРЕЗУЛЬТАТЫ:\\nАвтоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.\\n\\nУскорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.\\n\\nУлучшение управляемости и прозрачности коммуникаций внутри компании.\\n=======\\n***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы\\nСТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.\\n\\nЗАДАЧА:\\nАвтоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.\\n\\nРЕШЕНИЕ:\\n\\nПостроена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).\\n\\nВесь корпус структурирован в семантические коллекции по тематикам (например, \\\"регламенты\\\", \\\"учебные тексты\\\", \\\"терминология\\\").\\n\\nВнутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.\\n\\nПри поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.\\n\\nВыбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая \\\"галлюцинации\\\".\\n\\nРЕЗУЛЬТАТЫ:\\n\\nВремя получения ответа студентом — менее одной минуты.\\n\\nСущественное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.\\n\\nПовышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.\\n=======\\n***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)\\nСтек технологий (дополнено):\\nPython, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\\n\\nМетоды валидации LLM-ответов (через фреймворк RAGAS)\\nПРОБЛЕМА:\\nНеобходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.\\n\\nРЕШЕНИЕ:\\n\\n* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:\\n\\n    * эталонный ответ (ground truth),\\n\\n    * ссылки на источник (документ, раздел, страница),\\n\\n    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),\\n\\n    * корректное сопоставление извлечённого контекста с ожидаемым ответом.\\n\\nНа основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).\\n\\nКак работал RAGAS:\\nФреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.\\n\\nВ пайплайне применялись следующие метрики RAGAS:\\n\\n*Метрика*\\t  *Описание*\\n**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».\\n**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.\\n**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.\\n**context_precision** --> Соотношение между использованным и релевантным контекстом.\\n**context_recall** --> Насколько полно покрыт релевантный контекст.\\n**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.\\nРезультаты валидации:\\nВалидация дала чёткую картину сильных и слабых сторон модели:\\n\\nFaithfulness > — модель стабильно не «галлюцинирует» (или \\\"галлюцинирует\\\").\\n\\nAnswer relevancy >  — ответы соответствуют сути вопроса (или нет).\\n\\nМетрики context_precision/recall позволили оптимизировать retriever.\\n\\nПайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.\\n=======\\n***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций\\n\\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).\\n\\nЗАДАЧА:\\nПовысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.\\n\\nРЕШЕНИЕ:\\n\\nРазработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.\\n\\nСоздан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.\\n\\nФинальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.\\n\\nГотовый отчёт в формате PDF автоматически отправляется клиенту.\\n\\nРЕЗУЛЬТАТЫ:\\n\\nРост конверсии на 35% при сокращении расходов на колл-центр на 42%.\\n\\nЗначительный прирост дополнительной выручки уже в первые 6 месяцев.\\n\\nВысокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.\\n\\n#### Опыт работы #3: Контент-менеджер\\nПериод: 2022-07-01 - 2023-07-01\\nОписание: Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\\n\\n#### Опыт работы #4: автор студенческих работ\\nПериод: 2022-03-01 - 2023-05-01\\nОписание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\\n\\n#### Опыт работы #5: Автор студенческих работ\\nПериод: 2022-02-01 - 2023-02-01\\nОписание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).\\n\\n### Профессиональные роли\\n- Дата-сайентист\\n- Программист, разработчик\\n- Руководитель проектов\\n\\n### Предпочитаемые типы занятости\\n- Полная занятость\\n- Частичная занятость\\n- Проектная работа\\n\\n### Предпочитаемый график работы\\n- Полный день\\n- Гибкий график\\n- Удаленная работа\\n\\n### Знание языков\\n- Русский: Родной\\n- Английский: A1 — Начальный\\n- Итальянский: A1 — Начальный\\n\\n### Зарплатные ожидания\\n230000 руб.\\n\\n\\n        \\n        ## ВАКАНСИЯ\\n\\n### Описание вакансии\\nОбязанности:  Взаимодействие с заказчиками для сбора и уточнения требований Проектирование и разработка моделей машинного обучения (NLP) Внедрение современных подходов (fine-tuning, prompt-engineering, RAG) Организация процессов валидации моделей Управление командой из 3 датасайнтистов, распределение задач Внедрение методологий MLOps Взаимодействие с Data Architect, Data Analyst, Agile-командами, Data Engineer по вопросам обеспечения потребностей бизнеса в моделях  Требования:   Знание и понимание основных методов машинного обучения, глубокого обучения   Опыт использования LLM (написание промптов, RAG), работы с langchain   Опыт вывода моделей в промышленную эксплуатацию   Знания по терверу и мат. статистике и умение применять их на практике Pytorch  Хорошие аналитические и организационные навыки, коммуникабельность  Условия:  Амбициозные и нестандартные задачи, интересные проекты, возможность внедрять инновационные изменения Возможности внешнего и внутреннего обучения, доступ 24/7 к платформе дистанционного обучения Сбербанка: курсы, лекции, книги, ролики по актуальным направлениям Дружная команда с культурой поддержки и сотрудничества Комфортные условия работы в новом современном офисе в центре города  Ссылка на вакансию в банке вакансий на gsz.gov.⁣by: *Вакансия, планируемая к созданию (перспективная)\\n\\n### Ключевые навыки (требуемые)\\n- PyTorch\\n- NLP\\n- LLM\\n- LangChain\\n\\n### Требуемый опыт работы\\nОт 3 до 6 лет\\n\\n### Тип занятости\\nПолная занятость\\n\\n### График работы\\nПолный день\\n\\n\\n        \\n        ## Инструкции по анализу\\n        \\n        Проанализируй следующие разделы:\\n        \\n        1. **Заголовок резюме (title)** - соответствует ли заголовок названию вакансии и ключевым требованиям\\n        2. **Навыки (skills, skill_set)** - присутствуют ли все требуемые навыки из вакансии, какие навыки стоит добавить или выделить\\n        3. **Опыт работы (experience)** - соответствует ли опыт работы требуемому, насколько хорошо описаны релевантные проекты и достижения\\n        4. **Профессиональные роли (professional_roles)** - соответствуют ли указанные профессиональные роли требуемой позиции\\n        \\n        Для каждого раздела определи, что необходимо добавить, изменить или удалить для улучшения соответствия вакансии.\\n        \\n        ## Требования к формату ответа\\n        \\n        Верни ответ строго в формате JSON, соответствующий следующей структуре Pydantic модели ResumeGapAnalysis:\\n        \\n        ```\\n        {\\n            \\\"recommendations\\\": [\\n                {\\n                    \\\"section\\\": \\\"title\\\",\\n                    \\\"recommendation_type\\\": \\\"update\\\",\\n                    \\\"details\\\": [\\\"Изменить заголовок на...\\\", \\\"Добавить ключевые слова...\\\", \\\"Сделать акцент на...\\\"]\\n                },\\n                {\\n                    \\\"section\\\": \\\"skills\\\",\\n                    \\\"recommendation_type\\\": \\\"add\\\",\\n                    \\\"details\\\": [\\\"Добавить навык X...\\\", \\\"Подчеркнуть знание Y...\\\"]\\n                },\\n                // Другие рекомендации по всем разделам\\n            ]\\n        }\\n        ```\\n        \\n        ВАЖНО: Для каждого раздела (title, skills, skill_set, experience, professional_roles) должна быть как минимум одна рекомендация. Каждая рекомендация должна содержать не менее 3 конкретных пунктов в списке details. Рекомендации должны быть детальными и практичными.\\n        \"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Создаем экземпляр LLMGapAnalyzer\n",
    "gap_analyzer = LLMGapAnalyzer()\n",
    "\n",
    "# Получаем промпт для gap-анализа\n",
    "prompt = gap_analyzer._create_gap_analysis_prompt(parsed_resume_dict, parsed_vacancy_dict)\n",
    "\n",
    "# Выводим полный промпт без дополнительных сравнений\n",
    "print(\"=== ПОЛНЫЙ ПРОМПТ ДЛЯ LLM ===\")\n",
    "print(prompt)\n",
    "\n",
    "# Выводим полную структуру сообщений, как она отправляется в API\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"Ты — эксперт по рекрутингу и HR с глубоким пониманием IT-индустрии. \"\n",
    "            \"Твоя специализация — анализ соответствия резюме требованиям вакансий и предоставление \"\n",
    "            \"конкретных рекомендаций по улучшению. Всегда отвечай строго в формате JSON согласно \"\n",
    "            \"указанной структуре ResumeGapAnalysis. Рекомендации должны быть конкретными, \"\n",
    "            \"практичными и детальными, чтобы соискатель мог сразу применить их для улучшения резюме.\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n\\n=== ПОЛНАЯ СТРУКТУРА СООБЩЕНИЙ ДЛЯ API ===\")\n",
    "print(json.dumps(messages, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58cf4af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e3c060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7073dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01673b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2b153e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec745c7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semantic_venv)",
   "language": "python",
   "name": "semantic_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
