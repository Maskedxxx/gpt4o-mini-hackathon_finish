
        Перепиши резюме, учитывая результаты GAP-анализа.
        
        Данные текущего резюме:
        {'title': 'LLM Engineer', 'skills': 'Я - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.', 'skill_set': ['ChatGPT', 'AI', 'prompt', 'prompt engineering', 'Python', 'JSON API', 'Нейро-сотрудники', 'Умение работать в команде', 'Искусственный интеллект', 'Глубокое обучение', 'NLP', 'Машинное обучение', 'LLM', 'AI тренер', 'LangChain', 'Stable Diffusion', 'Чат-бот'], 'experience': [{'description': '***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\n\nСТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\n\nЗАДАЧА:\nАвтоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\n\nРЕШЕНИЕ:\nРазработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\n\nРЕЗУЛЬТАТЫ:\n\nСокращение времени создания поздравлений с нескольких часов до нескольких секунд.\n\nРост производительности до 100 поздравлений в день (ранее 5–10).\n\nПовышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\n=============================\n\n***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\n\nСТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\n\nЗАДАЧА:\nСоздать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\n\nРЕШЕНИЕ:\nРазработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\n\nИсходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\n\nЗапросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\n\nМодели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\n\nПроект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\n\nРЕЗУЛЬТАТЫ:\n\nПовышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.\n\nСнижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.\n\nРешение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.', 'position': 'AI engineer', 'start': '2024-05-01', 'end': None}, {'description': '***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\n\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\n\nЗАДАЧА:\nАвтоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\n\nРЕЩЕНИЕ:\nРазработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\n\nРеализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\n\nПроведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\n\nИспользованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\n\nРЕЗУЛЬТАТЫ:\nСокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\n\nДостигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\n\nОбеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\n=======\n***ПРОЕКТ***: Система автоматического аудита телефонных звонков\n\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)\n\nЗАДАЧА:\nАвтоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.\n\nРЕШЕНИЕ:\nРеализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.\n\nРазработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.\n\nПрименены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.\n\nРЕЗУЛЬТАТЫ:\nАвтоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.\n\nУскорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.\n\nУлучшение управляемости и прозрачности коммуникаций внутри компании.\n=======\n***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы\nСТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.\n\nЗАДАЧА:\nАвтоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.\n\nРЕШЕНИЕ:\n\nПостроена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).\n\nВесь корпус структурирован в семантические коллекции по тематикам (например, "регламенты", "учебные тексты", "терминология").\n\nВнутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.\n\nПри поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.\n\nВыбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая "галлюцинации".\n\nРЕЗУЛЬТАТЫ:\n\nВремя получения ответа студентом — менее одной минуты.\n\nСущественное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.\n\nПовышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.\n=======\n***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)\nСтек технологий (дополнено):\nPython, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\n\nМетоды валидации LLM-ответов (через фреймворк RAGAS)\nПРОБЛЕМА:\nНеобходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.\n\nРЕШЕНИЕ:\n\n* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:\n\n    * эталонный ответ (ground truth),\n\n    * ссылки на источник (документ, раздел, страница),\n\n    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),\n\n    * корректное сопоставление извлечённого контекста с ожидаемым ответом.\n\nНа основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).\n\nКак работал RAGAS:\nФреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.\n\nВ пайплайне применялись следующие метрики RAGAS:\n\n*Метрика*\t  *Описание*\n**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».\n**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.\n**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.\n**context_precision** --> Соотношение между использованным и релевантным контекстом.\n**context_recall** --> Насколько полно покрыт релевантный контекст.\n**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.\nРезультаты валидации:\nВалидация дала чёткую картину сильных и слабых сторон модели:\n\nFaithfulness > — модель стабильно не «галлюцинирует» (или "галлюцинирует").\n\nAnswer relevancy >  — ответы соответствуют сути вопроса (или нет).\n\nМетрики context_precision/recall позволили оптимизировать retriever.\n\nПайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.\n=======\n***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций\n\nСТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).\n\nЗАДАЧА:\nПовысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.\n\nРЕШЕНИЕ:\n\nРазработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.\n\nСоздан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.\n\nФинальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.\n\nГотовый отчёт в формате PDF автоматически отправляется клиенту.\n\nРЕЗУЛЬТАТЫ:\n\nРост конверсии на 35% при сокращении расходов на колл-центр на 42%.\n\nЗначительный прирост дополнительной выручки уже в первые 6 месяцев.\n\nВысокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.', 'position': 'AI engineer', 'start': '2023-08-01', 'end': '2024-05-01'}, {'description': 'Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.', 'position': 'Контент-менеджер', 'start': '2022-07-01', 'end': '2023-07-01'}, {'description': 'Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).', 'position': 'автор студенческих работ', 'start': '2022-03-01', 'end': '2023-05-01'}, {'description': 'Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).', 'position': 'Автор студенческих работ', 'start': '2022-02-01', 'end': '2023-02-01'}], 'employments': ['Полная занятость', 'Частичная занятость', 'Проектная работа'], 'schedules': ['Полный день', 'Гибкий график', 'Удаленная работа'], 'languages': [{'name': 'Русский', 'level': {'name': 'Родной'}}, {'name': 'Английский', 'level': {'name': 'A1 — Начальный'}}, {'name': 'Итальянский', 'level': {'name': 'A1 — Начальный'}}], 'relocation': {'type': {'name': 'не могу переехать'}}, 'salary': {'amount': 230000}, 'professional_roles': [{'name': 'Дата-сайентист'}, {'name': 'Программист, разработчик'}, {'name': 'Руководитель проектов'}]}
        
        Результаты GAP-анализа:
        {'recommendations': [{'section': 'title', 'recommendation_type': 'update', 'details': ["Изменить заголовок резюме с 'LLM Engineer' на более конкретный и соответствующий вакансии, например, 'ML Engineer / NLP Specialist с опытом работы с LLM и LangChain'.", "Включить в заголовок ключевые термины из вакансии, такие как 'PyTorch', 'RAG', 'MLOps', чтобы сразу выделить релевантный опыт.", "Сделать акцент на управленческих навыках, добавив упоминание о руководстве командой, например, 'Опыт управления командой data scientist'."]}, {'section': 'skills', 'recommendation_type': 'add', 'details': ['Добавить навык PyTorch как ключевой требуемый навык для вакансии, с указанием уровня владения.', 'Подчеркнуть глубокое знание NLP и LLM, расширив описание навыков, добавив методы fine-tuning и реализации RAG-систем.', 'Отдельно выделить опыт работы с MLOps и промышленной эксплуатацией моделей, включая опыт организационно-технического внедрения и CI/CD пайплайнов.']}, {'section': 'skill_set', 'recommendation_type': 'add', 'details': ['Включить раздел с конкретными технологиями и инструментами: PyTorch, Hugging Face Transformers, Docker, NVIDIA GPU, LangChain, Chroma, Pinecone.', 'Добавить навыки по статистике и теории вероятностей с указанием их практического применения в проектах ML.', 'Выделить знания и опыт в области организации валидации моделей и метрик качества, включая RAGAS и методологии валидации.']}, {'section': 'experience', 'recommendation_type': 'update', 'details': ['Уточнить описание проектов с акцентом на использование PyTorch для обучения и дообучения LLM, чтобы соответствовать вакансиям с упором на этот стек.', 'Более явно выделить опыт вывода моделей в промышленную эксплуатацию, описание MLOps-практик, использование Docker и CI/CD.', 'Добавить подробности о руководстве командой: управление 3 дата-сайентистами, распределение задач и организационные функции.']}, {'section': 'professional_roles', 'recommendation_type': 'update', 'details': ["Добавить в список профессиональных ролей позицию 'ML Engineer' или 'NLP Engineer', чтобы конкретизировать профиль.", 'Включить роль руководителя команды дата-сайентистов и опыт управления проектами ML.', 'Подчеркнуть коммуникативные и аналитические навыки, необходимые для взаимодействия с заказчиками и кросс-функциональными командами.']}]}
        
        Выполни следующие задачи:
        1. Измени заголовок резюме (title) в соответствии с рекомендациями
        2. Улучши описание навыков (skills) и список ключевых навыков (skill_set)
        3. Перепиши опыт работы (experience) согласно рекомендациям
        4. Обнови список профессиональных ролей (professional_roles) при необходимости
        
        Пожалуйста, используй профессиональный деловой стиль в описаниях.
        Перепиши ТОЛЬКО разделы, указанные в GAP-анализе, без изменения структуры резюме.
        
        Возврати ответ в формате JSON, соответствующий следующей структуре:
        ```
        {
            "title": "Обновленная должность",
            "skills": "Обновленное описание навыков...",
            "skill_set": ["Навык 1", "Навык 2", ...],
            "experience": [
                {
                    "position": "Должность 1",
                    "description": "Обновленное описание опыта работы..."
                },
                ...
            ],
            "professional_roles": [
                {
                    "name": "Название профессиональной роли"
                },
                ...
            ]
        }
        ```
        ВАЖНО: В разделе "experience" должно быть РОВНО столько же объектов, сколько их в исходном резюме!
        