#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –æ—Ç–≤–µ—Ç–∞ LLM –≤ GAP-–∞–Ω–∞–ª–∏–∑–µ.
–í—ã–∑—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç:
1. –û—Ç–≤–µ—Ç –æ—Ç LLM –≤ Pydantic —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
2. JSON –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
3. –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –ø–æ –ø–æ–ª—è–º –º–æ–¥–µ–ª–∏

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    python tests/debug_gap/debug_gap_response.py
"""

import json
import sys
import asyncio
from pathlib import Path
from typing import Dict, Any, Optional

# –î–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä–Ω–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ø—Ä–æ–µ–∫—Ç–∞ –≤ Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
from src.parsers.resume_extractor import ResumeExtractor
from src.parsers.vacancy_extractor import VacancyExtractor
from src.llm_gap_analyzer.llm_gap_analyzer import LLMGapAnalyzer
from src.models.gap_analysis_models import EnhancedResumeTailoringAnalysis
from src.utils.logging_config import setup_logging

def load_json_file(file_path: str) -> Optional[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {file_path}: {e}")
        return None

def show_gap_analysis_structure(gap_result: EnhancedResumeTailoringAnalysis) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ GAP-–∞–Ω–∞–ª–∏–∑–∞ –ø–æ –ø–æ–ª—è–º."""
    print("\n" + "="*80)
    print("üìä –°–¢–†–£–ö–¢–£–†–ê –†–ï–ó–£–õ–¨–¢–ê–¢–ê GAP-–ê–ù–ê–õ–ò–ó–ê")
    print("="*80)
    
    try:
        print("üî∏ –ü–ï–†–í–ò–ß–ù–´–ô –°–ö–†–ò–ù–ò–ù–ì:")
        ps = gap_result.primary_screening
        print(f"   ‚Ä¢ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –¥–æ–ª–∂–Ω–æ—Å—Ç–∏: {ps.job_title_match}")
        print(f"   ‚Ä¢ –î–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –æ–ø—ã—Ç: {ps.experience_years_match}")
        print(f"   ‚Ä¢ –í–∏–¥–Ω—ã –∫–ª—é—á–µ–≤—ã–µ –Ω–∞–≤—ã–∫–∏: {ps.key_skills_visible}")
        print(f"   ‚Ä¢ –ü–æ–¥—Ö–æ–¥—è—â–∞—è –ª–æ–∫–∞—Ü–∏—è: {ps.location_suitable}")
        print(f"   ‚Ä¢ –ó–∞—Ä–ø–ª–∞—Ç–Ω—ã–µ –æ–∂–∏–¥–∞–Ω–∏—è: {ps.salary_expectations_match}")
        print(f"   ‚Ä¢ –û–±—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {ps.overall_screening_result}")
        
        print("\nüî∏ –ê–ù–ê–õ–ò–ó –¢–†–ï–ë–û–í–ê–ù–ò–ô:")
        ra = gap_result.requirements_analysis
        must_have = [req for req in ra if req.requirement_type == "MUST_HAVE"]
        nice_to_have = [req for req in ra if req.requirement_type == "NICE_TO_HAVE"]
        bonus = [req for req in ra if req.requirement_type == "BONUS"]
        print(f"   ‚Ä¢ MUST-HAVE —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(must_have)}")
        print(f"   ‚Ä¢ NICE-TO-HAVE —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(nice_to_have)}")
        print(f"   ‚Ä¢ –ë–û–ù–£–° —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(bonus)}")
        print(f"   ‚Ä¢ –í—Å–µ–≥–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(ra)}")
        
        print("\nüî∏ –û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê:")
        qa = gap_result.quality_assessment
        print(f"   ‚Ä¢ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å: {qa.structure_clarity}/10")
        print(f"   ‚Ä¢ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è: {qa.content_relevance}/10")
        print(f"   ‚Ä¢ –§–æ–∫—É—Å –Ω–∞ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è: {qa.achievement_focus}/10")
        print(f"   ‚Ä¢ –ê–¥–∞–ø—Ç–∞—Ü–∏—è –ø–æ–¥ –≤–∞–∫–∞–Ω—Å–∏—é: {qa.adaptation_quality}/10")
        print(f"   ‚Ä¢ –û–±—â–µ–µ –≤–ø–µ—á–∞—Ç–ª–µ–Ω–∏–µ: {qa.overall_impression}")
        
        print("\nüî∏ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        print(f"   ‚Ä¢ –ö—Ä–∏—Ç–∏—á–Ω—ã—Ö: {len(gap_result.critical_recommendations)}")
        print(f"   ‚Ä¢ –í–∞–∂–Ω—ã—Ö: {len(gap_result.important_recommendations)}")
        print(f"   ‚Ä¢ –ñ–µ–ª–∞—Ç–µ–ª—å–Ω—ã—Ö: {len(gap_result.optional_recommendations)}")
        
        print("\nüî∏ –ò–¢–û–ì–û–í–´–ï –í–´–í–û–î–´:")
        print(f"   ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è: {gap_result.overall_match_percentage}%")
        print(f"   ‚Ä¢ –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è –ø–æ –Ω–∞–π–º—É: {gap_result.hiring_recommendation}")
        print(f"   ‚Ä¢ –ö–ª—é—á–µ–≤—ã—Ö —Å–∏–ª—å–Ω—ã—Ö —Å—Ç–æ—Ä–æ–Ω: {len(gap_result.key_strengths)}")
        print(f"   ‚Ä¢ –û—Å–Ω–æ–≤–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤: {len(gap_result.major_gaps)}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã: {e}")

def show_detailed_analysis(gap_result: EnhancedResumeTailoringAnalysis) -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–æ–≤."""
    print("\n" + "="*80)
    print("üìã –î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("="*80)
    
    try:
        # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ø–æ —Ç–∏–ø–∞–º
        requirements = gap_result.requirements_analysis
        
        # MUST-HAVE —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        must_have_reqs = [req for req in requirements if req.requirement_type == "MUST_HAVE"]
        if must_have_reqs:
            print("üî¥ MUST-HAVE –¢–†–ï–ë–û–í–ê–ù–ò–Ø:")
            for req in must_have_reqs:
                status_icon = "‚úÖ" if req.compliance_status == "–ü–û–õ–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ö†Ô∏è" if req.compliance_status == "–ß–ê–°–¢–ò–ß–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ùì" if req.compliance_status == "–¢–†–ï–ë–£–ï–¢_–£–¢–û–ß–ù–ï–ù–ò–Ø" else "‚ùå"
                print(f"   {status_icon} {req.requirement_text}")
                print(f"      –°—Ç–∞—Ç—É—Å: {req.compliance_status}")
                if req.evidence_in_resume:
                    print(f"      –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: {req.evidence_in_resume}")
                if req.gap_description:
                    print(f"      –ü—Ä–æ–±–µ–ª: {req.gap_description}")
        
        # NICE-TO-HAVE —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        nice_to_have_reqs = [req for req in requirements if req.requirement_type == "NICE_TO_HAVE"]
        if nice_to_have_reqs:
            print("\nüü° NICE-TO-HAVE –¢–†–ï–ë–û–í–ê–ù–ò–Ø:")
            for req in nice_to_have_reqs:
                status_icon = "‚úÖ" if req.compliance_status == "–ü–û–õ–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ö†Ô∏è" if req.compliance_status == "–ß–ê–°–¢–ò–ß–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ùì" if req.compliance_status == "–¢–†–ï–ë–£–ï–¢_–£–¢–û–ß–ù–ï–ù–ò–Ø" else "‚ùå"
                print(f"   {status_icon} {req.requirement_text}")
                print(f"      –°—Ç–∞—Ç—É—Å: {req.compliance_status}")
                if req.evidence_in_resume:
                    print(f"      –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: {req.evidence_in_resume}")
        
        # BONUS —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        bonus_reqs = [req for req in requirements if req.requirement_type == "BONUS"]
        if bonus_reqs:
            print("\nüü¢ –ë–û–ù–£–° –¢–†–ï–ë–û–í–ê–ù–ò–Ø:")
            for req in bonus_reqs:
                status_icon = "‚úÖ" if req.compliance_status == "–ü–û–õ–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ö†Ô∏è" if req.compliance_status == "–ß–ê–°–¢–ò–ß–ù–û–ï_–°–û–û–¢–í–ï–¢–°–¢–í–ò–ï" else \
                             "‚ùì" if req.compliance_status == "–¢–†–ï–ë–£–ï–¢_–£–¢–û–ß–ù–ï–ù–ò–Ø" else "‚ùå"
                print(f"   {status_icon} {req.requirement_text}")
                print(f"      –°—Ç–∞—Ç—É—Å: {req.compliance_status}")
        
        # –ö—Ä–∏—Ç–∏—á–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if gap_result.critical_recommendations:
            print("\nüö® –ö–†–ò–¢–ò–ß–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in gap_result.critical_recommendations:
                print(f"   ‚Ä¢ –°–µ–∫—Ü–∏—è: {rec.section}")
                print(f"     –ü—Ä–æ–±–ª–µ–º–∞: {rec.issue_description}")
                print(f"     –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å: {rec.criticality}")
                if rec.specific_actions:
                    print(f"     –î–µ–π—Å—Ç–≤–∏—è:")
                    for action in rec.specific_actions:
                        print(f"       - {action}")
                if rec.example_wording:
                    print(f"     –ü—Ä–∏–º–µ—Ä: {rec.example_wording}")
        
        # –í–∞–∂–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if gap_result.important_recommendations:
            print("\n‚ö†Ô∏è –í–ê–ñ–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in gap_result.important_recommendations:
                print(f"   ‚Ä¢ –°–µ–∫—Ü–∏—è: {rec.section}")
                print(f"     –ü—Ä–æ–±–ª–µ–º–∞: {rec.issue_description}")
                print(f"     –ö—Ä–∏—Ç–∏—á–Ω–æ—Å—Ç—å: {rec.criticality}")
                if rec.specific_actions:
                    print(f"     –î–µ–π—Å—Ç–≤–∏—è:")
                    for action in rec.specific_actions:
                        print(f"       - {action}")
        
        # –ñ–µ–ª–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if gap_result.optional_recommendations:
            print("\nüí° –ñ–ï–õ–ê–¢–ï–õ–¨–ù–´–ï –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
            for rec in gap_result.optional_recommendations:
                print(f"   ‚Ä¢ –°–µ–∫—Ü–∏—è: {rec.section}")
                print(f"     –ü—Ä–æ–±–ª–µ–º–∞: {rec.issue_description}")
                if rec.specific_actions:
                    print(f"     –î–µ–π—Å—Ç–≤–∏—è:")
                    for action in rec.specific_actions:
                        print(f"       - {action}")
        
        # –°–∏–ª—å–Ω—ã–µ —Å—Ç–æ—Ä–æ–Ω—ã –∏ –ø—Ä–æ–±–µ–ª—ã
        print(f"\nüí™ –ö–õ–Æ–ß–ï–í–´–ï –°–ò–õ–¨–ù–´–ï –°–¢–û–†–û–ù–´:")
        for strength in gap_result.key_strengths:
            print(f"   ‚Ä¢ {strength}")
        
        if gap_result.major_gaps:
            print(f"\nüîç –û–°–ù–û–í–ù–´–ï –ü–†–û–ë–ï–õ–´:")
            for gap in gap_result.major_gaps:
                print(f"   ‚Ä¢ {gap}")
        
        print(f"\nüìã –°–õ–ï–î–£–Æ–©–ò–ï –®–ê–ì–ò:")
        print(f"   {gap_result.next_steps}")
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")

async def debug_gap_analysis_response(resume_json_path: str, vacancy_json_path: str) -> None:
    """–í—ã–∑—ã–≤–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π GAP-–∞–Ω–∞–ª–∏–∑ –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
    print("\n" + "="*80)
    print("ü§ñ –†–ï–ó–£–õ–¨–¢–ê–¢ GAP-–ê–ù–ê–õ–ò–ó–ê –û–¢ LLM")
    print("="*80)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –ø–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
    raw_resume = load_json_file(resume_json_path)
    raw_vacancy = load_json_file(vacancy_json_path)
    
    if not (raw_resume and raw_vacancy):
        return
    
    # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ä—Å–µ—Ä—ã
    resume_extractor = ResumeExtractor()
    vacancy_extractor = VacancyExtractor()
    
    parsed_resume = resume_extractor.extract_resume_info(raw_resume)
    parsed_vacancy = vacancy_extractor.extract_vacancy_info(raw_vacancy)
    
    if not (parsed_resume and parsed_vacancy):
        print("‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö")
        return
    
    print("‚úÖ –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã, –∑–∞–ø—É—Å–∫–∞–µ–º GAP-–∞–Ω–∞–ª–∏–∑...")
    
    try:
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –∏ –∑–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
        gap_analyzer = LLMGapAnalyzer()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ dict –∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏
        resume_dict = parsed_resume.model_dump()
        vacancy_dict = parsed_vacancy.model_dump()
        
        # –í–´–ó–´–í–ê–ï–ú –†–ï–ê–õ–¨–ù–´–ô GAP-–ê–ù–ê–õ–ò–ó
        gap_result = await gap_analyzer.gap_analysis(resume_dict, vacancy_dict)
        
        if not gap_result:
            print("‚ùå GAP-–∞–Ω–∞–ª–∏–∑ –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            return
        
        print("‚úÖ GAP-–∞–Ω–∞–ª–∏–∑ —É—Å–ø–µ—à–Ω–æ –≤—ã–ø–æ–ª–Ω–µ–Ω!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ
        print(f"\nüìÑ –†–ï–ó–£–õ–¨–¢–ê–¢ –í JSON –§–û–†–ú–ê–¢–ï:")
        print("-" * 60)
        result_json = gap_result.model_dump()
        print(json.dumps(result_json, ensure_ascii=False, indent=2))
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        show_gap_analysis_structure(gap_result)
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        show_detailed_analysis(gap_result)
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è GAP-–∞–Ω–∞–ª–∏–∑–∞: {e}")

async def debug_pydantic_model_info() -> None:
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Pydantic –º–æ–¥–µ–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
    print("\n" + "="*80)
    print("üìö –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ú–û–î–ï–õ–ò EnhancedResumeTailoringAnalysis")
    print("="*80)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ö–µ–º—É –º–æ–¥–µ–ª–∏
        schema = EnhancedResumeTailoringAnalysis.model_json_schema()
        
        print("üî∏ –û–°–ù–û–í–ù–´–ï –ü–û–õ–Ø –ú–û–î–ï–õ–ò:")
        properties = schema.get('properties', {})
        for field_name, field_info in properties.items():
            field_type = field_info.get('type', 'unknown')
            description = field_info.get('description', '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')
            print(f"   ‚Ä¢ {field_name} ({field_type}): {description}")
        
        print(f"\nüî∏ –í–°–ï–ì–û –ü–û–õ–ï–ô –í –ú–û–î–ï–õ–ò: {len(properties)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º required –ø–æ–ª—è
        required = schema.get('required', [])
        print(f"üî∏ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–´–• –ü–û–õ–ï–ô: {len(required)}")
        for field in required:
            print(f"   ‚Ä¢ {field}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–æ–¥–µ–ª–∏: {e}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ—Ç–ª–∞–¥–∫–∏ –æ—Ç–≤–µ—Ç–∞ GAP-–∞–Ω–∞–ª–∏–∑–∞."""
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    setup_logging(log_level="INFO")
    
    print("üîç –û–¢–õ–ê–î–ö–ê –û–¢–í–ï–¢–ê LLM –í GAP-–ê–ù–ê–õ–ò–ó–ï")
    print("=" * 80)
    
    # ===============================================
    # –ù–ê–°–¢–†–û–ô–ö–ò –û–¢–õ–ê–î–ö–ò
    # ===============================================
    
    # –ü–£–¢–ò –ö JSON –§–ê–ô–õ–ê–ú
    resume_json_path = "path/to/your/resume.json"      # üëà –£–ö–ê–ñ–ò–¢–ï –ü–£–¢–¨ –ö –†–ï–ó–Æ–ú–ï
    vacancy_json_path = "path/to/your/vacancy.json"    # üëà –£–ö–ê–ñ–ò–¢–ï –ü–£–¢–¨ –ö –í–ê–ö–ê–ù–°–ò–ò
    
    # –§–õ–ê–ì–ò –£–ü–†–ê–í–õ–ï–ù–ò–Ø (True/False)
    run_gap_analysis = True        # üëà –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π GAP-–∞–Ω–∞–ª–∏–∑
    show_model_info = True         # üëà –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Pydantic –º–æ–¥–µ–ª–∏
    
    # ===============================================
    
    try:
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
        if show_model_info:
            await debug_pydantic_model_info()
        
        # –†–µ–∞–ª—å–Ω—ã–π GAP-–∞–Ω–∞–ª–∏–∑
        if run_gap_analysis:
            await debug_gap_analysis_response(resume_json_path, vacancy_json_path)
        
        print("\n" + "="*80)
        print("‚úÖ –û–¢–õ–ê–î–ö–ê –û–¢–í–ï–¢–ê GAP-–ê–ù–ê–õ–ò–ó–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print("="*80)
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    asyncio.run(main())