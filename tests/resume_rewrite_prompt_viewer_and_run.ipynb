{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa572fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Резюме файл существует: True\n",
      "Gap-анализ файл существует: True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "\n",
    "# Добавляем корневую директорию проекта в пути импорта\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "# Импортируем необходимые модули\n",
    "from src.parsers.resume_extractor import ResumeExtractor\n",
    "from src.llm_update_resume.llm_resume_updater import LLMResumeUpdater\n",
    "from src.models.gap_analysis_models import ResumeTailoringAnalysis\n",
    "\n",
    "# Пути к файлам\n",
    "resume_file_path = Path(\"tests/fetched_resume_6d807532ff0ed6b79f0039ed1f63386d724a62.json\")\n",
    "gap_analysis_path = Path(\"gap_analysis_result.json\")  # Путь к сохраненному результату gap-анализа\n",
    "\n",
    "# Проверяем наличие файлов\n",
    "print(f\"Резюме файл существует: {resume_file_path.exists()}\")\n",
    "print(f\"Gap-анализ файл существует: {gap_analysis_path.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "443aa8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные резюме успешно загружены\n",
      "Данные gap-анализа успешно загружены\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "try:\n",
    "    with open(resume_file_path, 'r', encoding='utf-8') as f:\n",
    "        resume_data = json.load(f)\n",
    "    print(\"Данные резюме успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при загрузке данных резюме: {e}\")\n",
    "    resume_data = None\n",
    "\n",
    "try:\n",
    "    with open(gap_analysis_path, 'r', encoding='utf-8') as f:\n",
    "        gap_analysis_data = json.load(f)\n",
    "    print(\"Данные gap-анализа успешно загружены\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при загрузке данных gap-анализа: {e}\")\n",
    "    gap_analysis_data = None\n",
    "\n",
    "# Парсим данные резюме\n",
    "resume_parser = ResumeExtractor()\n",
    "parsed_resume = resume_parser.extract_resume_info(resume_data) if resume_data else None\n",
    "parsed_resume_dict = parsed_resume.model_dump() if parsed_resume else None\n",
    "\n",
    "# Создаем объект ResumeGapAnalysis из JSON\n",
    "gap_result = ResumeTailoringAnalysis.model_validate(gap_analysis_data) if gap_analysis_data else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "629f344b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные резюме успешно загружены\n",
      "Данные gap-анализа успешно загружены\n",
      "✅ Данные резюме и gap-анализа успешно загружены и валидированы\n"
     ]
    }
   ],
   "source": [
    "# Загружаем данные\n",
    "with open(resume_file_path, 'r', encoding='utf-8') as f:\n",
    "    resume_data = json.load(f)\n",
    "print(\"Данные резюме успешно загружены\")\n",
    "\n",
    "with open(gap_analysis_path, 'r', encoding='utf-8') as f:\n",
    "    gap_analysis_data = json.load(f)\n",
    "print(\"Данные gap-анализа успешно загружены\")\n",
    "\n",
    "# Парсим данные резюме\n",
    "resume_parser = ResumeExtractor()\n",
    "parsed_resume = resume_parser.extract_resume_info(resume_data)\n",
    "parsed_resume_dict = parsed_resume.model_dump()\n",
    "\n",
    "# Создаем объект ResumeGapAnalysis из JSON\n",
    "gap_result = ResumeTailoringAnalysis.model_validate(gap_analysis_data)\n",
    "\n",
    "print(\"✅ Данные резюме и gap-анализа успешно загружены и валидированы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d43ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ПОЛНЫЙ ПРОМПТ ДЛЯ ФИНАЛЬНОГО РЕРАЙТА РЕЗЮМЕ ===\n",
      "\n",
      "        # ЗАДАЧА: УЛУЧШЕНИЕ РЕЗЮМЕ НА ОСНОВЕ GAP-АНАЛИЗА\n",
      "        \n",
      "        Твоя задача - переписать резюме соискателя, учитывая рекомендации из GAP-анализа, чтобы повысить его шансы на получение желаемой позиции.\n",
      "        \n",
      "        ## ТЕКУЩЕЕ РЕЗЮМЕ ДЛЯ АНАЛИЗА\n",
      "\n",
      "### Желаемая должность\n",
      "LLM Engineer\n",
      "\n",
      "### Описание навыков (общее)\n",
      "Я - увлеченный специалист, который видит потенциал искусственного интеллекта в упрощении жизни людей и бизнеса. Люблю копаться в LangChain и изучаю как работаю векторные базы данных. Считаю prompt engineering одним из основных навыков для создания грамотных LLM приложений.\n",
      "\n",
      "### Ключевые навыки (список)\n",
      "- ChatGPT\n",
      "- AI\n",
      "- prompt\n",
      "- prompt engineering\n",
      "- Python\n",
      "- JSON API\n",
      "- Нейро-сотрудники\n",
      "- Умение работать в команде\n",
      "- Искусственный интеллект\n",
      "- Глубокое обучение\n",
      "- NLP\n",
      "- Машинное обучение\n",
      "- LLM\n",
      "- AI тренер\n",
      "- LangChain\n",
      "- Stable Diffusion\n",
      "- Чат-бот\n",
      "\n",
      "### Опыт работы\n",
      "#### Опыт работы (ID: ОПЫТ_ID_1 [Компания не указана - AI engineer])\n",
      "Период: 2024-05-01 - None\n",
      "Оригинальное описание: ***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Сокращение времени создания поздравлений с нескольких часов до нескольких секунд.\n",
      "\n",
      "Рост производительности до 100 поздравлений в день (ранее 5–10).\n",
      "\n",
      "Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\n",
      "=============================\n",
      "\n",
      "***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\n",
      "\n",
      "ЗАДАЧА:\n",
      "Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\n",
      "\n",
      "Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\n",
      "\n",
      "Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\n",
      "\n",
      "Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\n",
      "\n",
      "Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем.\n",
      "\n",
      "Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму.\n",
      "\n",
      "Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\n",
      "\n",
      "#### Опыт работы (ID: ОПЫТ_ID_2 [Компания не указана - AI engineer])\n",
      "Период: 2023-08-01 - 2024-05-01\n",
      "Оригинальное описание: ***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\n",
      "\n",
      "РЕЩЕНИЕ:\n",
      "Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\n",
      "\n",
      "Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\n",
      "\n",
      "Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\n",
      "\n",
      "Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\n",
      "\n",
      "Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\n",
      "\n",
      "Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\n",
      "=======\n",
      "***ПРОЕКТ***: Система автоматического аудита телефонных звонков\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, JSON-структурирование данных, методы промпт-инженерии (Self-Reflection, Decomposition)\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать аудит телефонных разговоров, обеспечить точность и объективность анализа диалогов операторов с клиентами, снизить влияние человеческого фактора.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "Реализована автоматизированная система на основе GPT-4, которая прослушивает записи телефонных звонков, выделяет и оценивает ключевые аспекты диалогов.\n",
      "\n",
      "Разработан механизм генерации детализированных отчётов в формате JSON, что упрощает последующую аналитику и контроль качества коммуникаций.\n",
      "\n",
      "Применены методы промпт-инженерии (Self-Reflection, Decomposition), позволяющие модели самостоятельно уточнять и корректировать собственные результаты анализа для повышения их точности.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "Автоматизированный и объективный аудит звонков, исключающий ошибки человеческого фактора.\n",
      "\n",
      "Ускорение процесса аудита и улучшение качества клиентского обслуживания за счёт оперативного выявления и исправления проблем.\n",
      "\n",
      "Улучшение управляемости и прозрачности коммуникаций внутри компании.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для ответов на вопросы студентов астрологической школы\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, LangChain, LlamaIndex, GPT-4, Chroma, BM-25, векторное индексирование, семантическое разбиение, кастомные цепочки извлечения контекста, гибридный поиск.\n",
      "\n",
      "ЗАДАЧА:\n",
      "Автоматизировать ответы на вопросы студентов по обширной учебной документации (лекции, пособия, положения, регламенты) — с высокой скоростью и точностью, без галлюцинаций.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Построена RAG-система (Retrieval-Augmented Generation) на корпусе астрологической школы (тысячи страниц).\n",
      "\n",
      "Весь корпус структурирован в семантические коллекции по тематикам (например, \"регламенты\", \"учебные тексты\", \"терминология\").\n",
      "\n",
      "Внутри каждой коллекции текст представлен в виде иерархической карты знаний (главы → подглавы → разделы → подразделы) с метаинформацией: summary и ключевые слова, привязанные к структуре документа.\n",
      "\n",
      "При поступлении вопроса осуществляется поэтапный семантический роутинг — от определения релевантной главы до точного участка внутри подраздела.\n",
      "\n",
      "Выбранный текстовый фрагмент передаётся в GPT-4, что гарантирует генерацию точного, релевантного и достоверного ответа, исключая \"галлюцинации\".\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Время получения ответа студентом — менее одной минуты.\n",
      "\n",
      "Существенное улучшение качества обучения: доступ к детальным, проверенным ответам без ожидания куратора.\n",
      "\n",
      "Повышена релевантность за счёт глубокого индексирования и точного соответствия ответа исходному тексту.\n",
      "=======\n",
      "***ПРОЕКТ***: RAG-система для студентов астрологической школы (дополнение: ВАЛИДАЦИЯ ответов)\n",
      "Стек технологий (дополнено):\n",
      "Python, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\n",
      "\n",
      "Методы валидации LLM-ответов (через фреймворк RAGAS)\n",
      "ПРОБЛЕМА:\n",
      "Необходимо было обеспечить достоверность и релевантность ответов, сгенерированных RAG-системой на основе большого корпуса (лекции, регламенты, учебники), и провести метрическую верификацию качества модели.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "* Мы подготовили размеченный датасет из 100+ вопросов, каждый из которых содержал:\n",
      "\n",
      "    * эталонный ответ (ground truth),\n",
      "\n",
      "    * ссылки на источник (документ, раздел, страница),\n",
      "\n",
      "    * семантически выверенные chunk’и контекста (метаданные: collection → document → section → page),\n",
      "\n",
      "    * корректное сопоставление извлечённого контекста с ожидаемым ответом.\n",
      "\n",
      "На основе этого датасета реализован валидационный пайплайн с использованием RAGAS (Retrieval-Augmented Generation Assessment).\n",
      "\n",
      "Как работал RAGAS:\n",
      "Фреймворк RAGAS позволил автоматически проверять качество каждого ответа, используя как сам ответ модели, так и вопрос, извлечённые chunk-и и (при наличии) эталонный ответ.\n",
      "\n",
      "В пайплайне применялись следующие метрики RAGAS:\n",
      "\n",
      "*Метрика*\t  *Описание*\n",
      "**faithfulness**-->Насколько сгенерированный ответ соответствует извлечённому контексту, отсутствуют ли «галлюцинации».\n",
      "**context_relevancy** --> Оценивает, насколько выбранные документы действительно релевантны запросу.\n",
      "**answer_relevancy** --> Насколько ответ отвечает на исходный вопрос.\n",
      "**context_precision** --> Соотношение между использованным и релевантным контекстом.\n",
      "**context_recall** --> Насколько полно покрыт релевантный контекст.\n",
      "**answer_similarity** --> Семантическое сходство между сгенерированным и эталонным ответом.\n",
      "Результаты валидации:\n",
      "Валидация дала чёткую картину сильных и слабых сторон модели:\n",
      "\n",
      "Faithfulness > — модель стабильно не «галлюцинирует» (или \"галлюцинирует\").\n",
      "\n",
      "Answer relevancy >  — ответы соответствуют сути вопроса (или нет).\n",
      "\n",
      "Метрики context_precision/recall позволили оптимизировать retriever.\n",
      "\n",
      "Пайплайн встроен в CI, что позволило отслеживать деградации качества модели при обновлениях RAG-инфраструктуры.\n",
      "=======\n",
      "***ПРОЕКТ***: Чат-бот для автоматизации продаж и клиентских консультаций\n",
      "\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, LangChain, LlamaIndex, методы промпт-инженерии, динамические цепочки вызовов модели, AstrService (генерация натальных карт), PyMuPDF (генерация PDF-документов с визуализацией).\n",
      "\n",
      "ЗАДАЧА:\n",
      "Повысить эффективность воронки продаж и снизить расходы на клиентский сервис через автоматизацию консультаций и персонализированное общение с клиентами.\n",
      "\n",
      "РЕШЕНИЕ:\n",
      "\n",
      "Разработан чат-бот на базе GPT-4 с персонализированным подходом к продажам и консультированию клиентов.\n",
      "\n",
      "Создан собственный сервис AstrService для генерации натальных карт по дате и месту рождения клиента, на основе которых GPT-4 формирует персонализированные консультации через цепочку из 9 отдельных вызовов.\n",
      "\n",
      "Финальный результат автоматически собирается в PDF-документ с визуализацией натальной карты, текстом консультации от GPT-4, красивым шрифтом и элементами анимации с использованием библиотеки PyMuPDF.\n",
      "\n",
      "Готовый отчёт в формате PDF автоматически отправляется клиенту.\n",
      "\n",
      "РЕЗУЛЬТАТЫ:\n",
      "\n",
      "Рост конверсии на 35% при сокращении расходов на колл-центр на 42%.\n",
      "\n",
      "Значительный прирост дополнительной выручки уже в первые 6 месяцев.\n",
      "\n",
      "Высокая удовлетворённость клиентов благодаря уникальному персонализированному подходу и качественной подаче информации.\n",
      "\n",
      "#### Опыт работы (ID: ОПЫТ_ID_3 [Компания не указана - Контент-менеджер])\n",
      "Период: 2022-07-01 - 2023-07-01\n",
      "Оригинальное описание: Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\n",
      "\n",
      "#### Опыт работы (ID: ОПЫТ_ID_4 [Компания не указана - автор студенческих работ])\n",
      "Период: 2022-03-01 - 2023-05-01\n",
      "Оригинальное описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\n",
      "\n",
      "#### Опыт работы (ID: ОПЫТ_ID_5 [Компания не указана - Автор студенческих работ])\n",
      "Период: 2022-02-01 - 2023-02-01\n",
      "Оригинальное описание: Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, (12 закрытых заказов).\n",
      "\n",
      "### Профессиональные роли\n",
      "- Дата-сайентист\n",
      "- Программист, разработчик\n",
      "- Руководитель проектов\n",
      "\n",
      "\n",
      "        \n",
      "        ## ЗАДАНИЕ НА АДАПТАЦИЮ РЕЗЮМЕ (ОТЧЕТ ОТ LLM-АНАЛИТИКА)\n",
      "\n",
      "### 1. Предлагаемый заголовок резюме (Желаемая должность):\n",
      "LLM Engineer / AI Engineer с опытом работы с LangChain и RAG\n",
      "\n",
      "### 2. Рекомендации для 'Описания навыков' (общее summary):\n",
      "Предлагаемая основа для переписывания:\n",
      "Добавьте в описание навыков и раздел ключевых навыков чёткие упоминания PyTorch и опыта промышленного развёртывания моделей, а также выделите навыки управления командой и MLOps. Отразите опыт работы с RAG, fine-tuning и методологиями валидации моделей. В описании добавьте упоминания взаимодействия с Agile-командами и сопутствующими ролями (Data Architect, Data Analyst, Data Engineer).\n",
      "\n",
      "### 3. Рекомендуемый 'Ключевой набор навыков' (список):\n",
      "- PyTorch\n",
      "- NLP\n",
      "- LLM\n",
      "- LangChain\n",
      "- Prompt Engineering\n",
      "- RAG\n",
      "- Fine-tuning моделей\n",
      "- MLOps\n",
      "- Валидация моделей\n",
      "- Управление командой\n",
      "- Аналитические навыки\n",
      "- Коммуникабельность\n",
      "\n",
      "### 4. Инструкции по адаптации опыта работы:\n",
      "\n",
      "#### 4.1 Для опыта (ID: Опыт работы #1: AI engineer)\n",
      "**Оригинальное описание (для контекста LLM-копирайтера):**\n",
      "***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\n",
      "ЗАДАЧА: Автоматизировать ручной процесс создания голосовых поздравлений сотрудников, ранее занимавший несколько часов и требовавший участия оператора.\n",
      "РЕШЕНИЕ: Разработан Telegram-бот, который автоматически генерирует персонализированные аудио-поздравления с корректным склонением имён и выбором голоса. Интегрирован с внутренними системами компании для прямой доставки сообщений сотрудникам.\n",
      "РЕЗУЛЬТАТЫ: Сокращение времени создания поздравлений с нескольких часов до нескольких секунд. Рост производительности до 100 поздравлений в день (ранее 5–10). Повышение единообразия и точности корпоративной коммуникации, исключение человеческих ошибок.\n",
      "=============================\n",
      "***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM (миграция), Chroma (основное хранилище векторов), Pinecone (тестирование), Docker, NVIDIA GPU\n",
      "ЗАДАЧА: Создать систему точного семантического роутинга и автоматизированного ответа на вопросы сотрудников по внутренней документации, заменив менее точные методы поиска и ручную работу операторов.\n",
      "РЕШЕНИЕ: Разработан многоуровневый ансамбль локальных LLM (Llama 3 — модели 7B и 70B) с использованием semantic_router и Ollama для точного семантического роутинга и генерации ответов без классического векторного поиска.\n",
      "Исходные документы (HTML, Word, PDF) преобразуются в структурированный JSON.\n",
      "Запросы автоматически разделяются на шесть подвопросов, для которых независимо определяется категория. Конечный выбор осуществляется голосованием большинства.\n",
      "Модели эмбеддингов дообучаются на размеченной позитивной обратной связи, вектора индексируются и хранятся в Chroma (тестируем миграцию на Pinecone для улучшения сбора метрик).\n",
      "Проект развёрнут в Docker-контейнере на локальном сервере с GPU от NVIDIA, выполняется постепенный переход на фреймворк vLLM для эффективного локального инференса.\n",
      "РЕЗУЛЬТАТЫ: Повышение точности маршрутизации запросов на ~40% за счёт обучения с учителем. Снижение количества ошибок при выборе файлов на 50% благодаря голосующему механизму. Решение успешно внедрено в 4 отделах компании, обеспечивая высокую масштабируемость и возможность тиражирования.\n",
      "\n",
      "**Общая оценка и стратегия адаптации от LLM-аналитика:**\n",
      "Опыт демонстрирует глубокое владение технологиями LLM, LangChain, RAG и промышленным развёртыванием в Docker/GPU-средах. Проекты подробно описаны с акцентом на результаты и сложность задач, что хорошо соответствует требованиям вакансии, включая навыки промпт-инжиниринга и семантического роутинга.\n",
      "\n",
      "**Конкретные инструкции по изменению от LLM-аналитика:**\n",
      "  Инструкция #1:\n",
      "    Действие: UPDATE\n",
      "    Целевой фрагмент (из оригинала): \"Telegram-бот для автоматизации поздравлений сотрудников (синтез речи)\"\n",
      "    Детали инструкции: Добавьте короткое описание, как проект связан с NLP и LLM, подчеркните использование Python для разработки. Укажите, если была организована автоматизация с акцентом на качество моделей и интеграцию с бизнес-процессами.\n",
      "    Обоснование (релевантность вакансии): Вакансия требует опыта с NLP и промышленным применением LLM, поэтому важно показать, что в проекте использовались соответствующие технологии и подходы.\n",
      "\n",
      "  Инструкция #2:\n",
      "    Действие: UPDATE\n",
      "    Целевой фрагмент (из оригинала): \"Корпоративный интеллектуальный поиск и автоответчик на основе LLM\"\n",
      "    Детали инструкции: Укажите явный опыт с LangChain, RAG, fine-tuning и использованием Docker/GPU для развёртывания моделей. Выделите аналитические и организационные успехи, а также применение валидации моделей и взаимодействие с командами (Data Architect, Data Engineer).\n",
      "    Обоснование (релевантность вакансии): Проект демонстрирует релевантные навыки и опыт, соответствующий требованиям вакансии по LLM, промышленному развёртыванию и взаимодействию в команде.\n",
      "\n",
      "  Инструкция #3:\n",
      "    Действие: ADD\n",
      "    Детали инструкции: В начало опыта работы добавьте краткое резюме, отражающее 3+ лет опыта в машиенном обучении с акцентом на LLM и промышленное внедрение. Отметьте опыт руководства и MLOps.\n",
      "    Обоснование (релевантность вакансии): В вакансии требуется опыт от 3 до 6 лет, управление командой и MLOps, что нужно явно показать в описании опыта.\n",
      "\n",
      "\n",
      "#### 4.2 Для опыта (ID: Опыт работы #2: AI engineer)\n",
      "**Оригинальное описание (для контекста LLM-копирайтера):**\n",
      "***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\n",
      "СТЕК ТЕХНОЛОГИЙ: Python, GPT-4, GPT-3.5, Pinecone (гибридный и семантический поиск), Pymorphy2, методы промпт-инженерии (CoT, ToT), дообучение LLM, API.\n",
      "ЗАДАЧА: Автоматизировать проверку домашних заданий на образовательной платформе, ранее занимавшую до 65% времени кураторов, что замедляло обратную связь и снижало эффективность обучения.\n",
      "РЕЩЕНИЕ: Разработаны 4 чат-бота на Python с интеграцией LLM, автоматизирующие проверку домашних заданий по разным дисциплинам.\n",
      "Реализована гибридная система поиска и проверки ответов студентов через Pinecone и морфологический анализ запросов с помощью Pymorphy2.\n",
      "Проведено дообучение модели GPT-3.5 на 900 страницах контента и 1200 парах вопрос-ответ, улучшив качество ответов и снизив расходы на запросы.\n",
      "Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought) для повышения точности и эффективности проверки.\n",
      "РЕЗУЛЬТАТЫ: Сокращено время проверки домашних заданий, повысилась оперативность и качество обратной связи студентам.\n",
      "Достигнута экономическая эффективность: Экономия ~30% от годовых расходов на ручную проверку.\n",
      "Обеспечено стабильное и качественное выполнение проверок без человеческого фактора, что повысило общую удовлетворённость учащихся и кураторов.\n",
      "\n",
      "**Общая оценка и стратегия адаптации от LLM-аналитика:**\n",
      "Опыт хорошо отражает навыки в LLM, Python, работе с гибридным поиском и методах prompt engineering, включая дообучение моделей. Хорошо описаны результаты и экономический эффект, что соответствует требуемой экспертизе.\n",
      "\n",
      "**Конкретные инструкции по изменению от LLM-аналитика:**\n",
      "  Инструкция #1:\n",
      "    Действие: UPDATE\n",
      "    Целевой фрагмент (из оригинала): \"Чат-боты-кураторы на базе LLM для автоматизации проверки заданий\"\n",
      "    Детали инструкции: Добавьте акцент на опыт промышленного вывода и поддержку моделей в рабочей среде, а также на работу с LangChain и Agile-методами.\n",
      "    Обоснование (релевантность вакансии): Необходимо показать опыт вывода моделей в промышленную эксплуатацию и взаимодействия с командами, что важно для вакансии.\n",
      "\n",
      "  Инструкция #2:\n",
      "    Действие: ADD\n",
      "    Детали инструкции: В конце описания добавьте информацию о коммуникации с другими ролями (Data Engineer, Data Analyst) и управлении проектом.\n",
      "    Обоснование (релевантность вакансии): Вакансия требует навыков межкомандного взаимодействия и управления процессами.\n",
      "\n",
      "  Инструкция #3:\n",
      "    Действие: UPDATE\n",
      "    Целевой фрагмент (из оригинала): \"Использованы передовые методы промпт-инженерии (Chain of Thought, Tree of Thought)\"\n",
      "    Детали инструкции: Раскройте применение RAG и fine-tuning технологий, укажите участие в организации валидационных процессов моделей.\n",
      "    Обоснование (релевантность вакансии): Эти навыки важны для соответствия вакансии и отделяют продвинутого специалиста.\n",
      "\n",
      "\n",
      "#### 4.3 Для опыта (ID: Опыт работы #3: Контент-менеджер)\n",
      "**Оригинальное описание (для контекста LLM-копирайтера):**\n",
      "Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний, поддержание и обновление портфолио текстов, коллаборация с другими отделами, контроль качества и бренда компании в выпускаемых материалах.\n",
      "\n",
      "**Общая оценка и стратегия адаптации от LLM-аналитика:**\n",
      "Опыт менее релевантен для технической позиции LLM Engineer. Может быть кратко упомянут для иллюстрации коммуникационных навыков, но не нужно делать на нём акцент.\n",
      "\n",
      "**Конкретные инструкции по изменению от LLM-аналитика:**\n",
      "  Инструкция #1:\n",
      "    Действие: DELETE\n",
      "    Целевой фрагмент (из оригинала): \"Создание и редактирование текстов, разработка стратегий коммуникации и маркетинговых кампаний\"\n",
      "    Детали инструкции: Сократите подробности этого опыта или уберите из основного блока, оставив его лишь упоминанием в профессиональных ролях или дополнительной информации.\n",
      "    Обоснование (релевантность вакансии): Для LLM Engineer основной фокус должен быть на техническом опыте и навыках, не на контент-менеджменте.\n",
      "\n",
      "  Инструкция #2:\n",
      "    Действие: ADD\n",
      "    Детали инструкции: Если оставлять, выделите в этом опыте навыки организации, коммуникации и работы в команде.\n",
      "    Обоснование (релевантность вакансии): Коммуникабельность и командная работа требуются для вакансии, и этот опыт может это подтвердить.\n",
      "\n",
      "  Инструкция #3:\n",
      "    Действие: UPDATE\n",
      "    Детали инструкции: Рассмотрите возможность свести описание к одной-двум строкам и выдвинуть на первый план навыки работы с командами и менеджмента.\n",
      "    Обоснование (релевантность вакансии): Так описание будет сбалансированным и поможет не перегрузить резюме.\n",
      "\n",
      "\n",
      "#### 4.4 Для опыта (ID: Опыт работы #4: автор студенческих работ)\n",
      "**Оригинальное описание (для контекста LLM-копирайтера):**\n",
      "Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов, ( 6 закрытых заказов).\n",
      "\n",
      "**Общая оценка и стратегия адаптации от LLM-аналитика:**\n",
      "Опыт не относится к требуемой позиции инженер LLM и не добавляет ценности в контексте вакансии.\n",
      "\n",
      "**Конкретные инструкции по изменению от LLM-аналитика:**\n",
      "  Инструкция #1:\n",
      "    Действие: DELETE\n",
      "    Целевой фрагмент (из оригинала): \"Работа с научными работами: опыт в редактировании и написании курсовых и дипломных проектов\"\n",
      "    Детали инструкции: Рекомендуется удалить этот опыт из основного резюме, чтобы не отвлекать от релевантного опыта.\n",
      "    Обоснование (релевантность вакансии): Низкая релевантность к позиции LLM Engineer.\n",
      "\n",
      "  Инструкция #2:\n",
      "    Действие: ADD\n",
      "    Детали инструкции: Если нужно, оставьте упоминание в разделе «Дополнительная информация» или «Прочее».\n",
      "    Обоснование (релевантность вакансии): Для полноты портфолио, не в основное резюме.\n",
      "\n",
      "  Инструкция #3:\n",
      "    Действие: UPDATE\n",
      "    Детали инструкции: В случае сохранения свяжите опыт с навыками работы с текстами и аналитики, но минимально.\n",
      "    Обоснование (релевантность вакансии): Это поможет сгладить переход к более техническим блокам.\n",
      "\n",
      "\n",
      "        \n",
      "        ## ИНСТРУКЦИИ ПО УЛУЧШЕНИЮ\n",
      "        \n",
      "        1. Переработай каждый раздел резюме согласно рекомендациям выше\n",
      "        2. Сохрани структуру и количество элементов опыта работы - их должно быть столько же, сколько в исходном резюме\n",
      "        3. Используй профессиональный деловой стиль в описаниях\n",
      "        4. Сфокусируйся на конкретных достижениях и релевантном опыте\n",
      "        5. Используй ключевые слова из рекомендаций\n",
      "        \n",
      "        ## ФОРМАТ ОТВЕТА\n",
      "        \n",
      "        Верни ответ строго в формате JSON, соответствующий структуре Pydantic модели ResumeUpdate:\n",
      "        \n",
      "        ```json\n",
      "        {\n",
      "            \"title\": \"Обновленная должность\",\n",
      "            \"skills\": \"Обновленное описание навыков...\",\n",
      "            \"skill_set\": [\"Навык 1\", \"Навык 2\", ...],\n",
      "            \"experience\": [\n",
      "                {\n",
      "                    \"position\": \"Должность 1\",\n",
      "                    \"description\": \"Обновленное описание опыта работы...\"\n",
      "                },\n",
      "                ...\n",
      "            ],\n",
      "            \"professional_roles\": [\n",
      "                {\n",
      "                    \"name\": \"Название профессиональной роли\"\n",
      "                },\n",
      "                ...\n",
      "            ]\n",
      "        }\n",
      "        ```\n",
      "        \n",
      "        ВАЖНО: Раздел \"experience\" должен содержать ровно 5 объектов - столько же, сколько в исходном резюме.\n",
      "        \n",
      "\n",
      "Форматированный промпт сохранен в файл: formatted_rewrite_prompt.txt\n"
     ]
    }
   ],
   "source": [
    "# Создаем экземпляр LLMResumeUpdater\n",
    "resume_updater = LLMResumeUpdater()\n",
    "\n",
    "# Получаем промпт для финального рерайта резюме\n",
    "prompt = resume_updater._create_final_rewrite_prompt(parsed_resume_dict, gap_result)\n",
    "\n",
    "# Выводим полный промпт\n",
    "print(\"\\n=== ПОЛНЫЙ ПРОМПТ ДЛЯ ФИНАЛЬНОГО РЕРАЙТА РЕЗЮМЕ ===\")\n",
    "print(prompt)\n",
    "\n",
    "# Сохраняем промпт в файл для более удобного изучения\n",
    "prompt_file_path = Path(\"formatted_rewrite_prompt.txt\")\n",
    "with open(prompt_file_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(prompt)\n",
    "print(f\"\\nФорматированный промпт сохранен в файл: {prompt_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9475beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ЗАПУСК ФИНАЛЬНОГО РЕРАЙТА РЕЗЮМЕ ===\n",
      "Отправляем запрос к LLM API...\n",
      "\n",
      "✅ Резюме успешно обновлено!\n",
      "\n",
      "=== ПОЛНЫЙ JSON РЕЗУЛЬТАТА ===\n",
      "{\n",
      "  \"title\": \"LLM Engineer / AI Engineer с опытом работы с LangChain и RAG\",\n",
      "  \"skills\": \"Специалист с более чем 3-летним опытом в сфере машинного обучения с акцентом на разработку и промышленное внедрение моделей LLM. Эксперт в PyTorch, LangChain и методах prompt engineering для создания эффективных AI-приложений. Практический опыт реализации сложных RAG-систем, fine-tuning моделей и организации процессов валидации с использованием современных фреймворков. Владение технологиями MLOps для развёртывания и поддержки моделей в продуктивной среде с Docker и GPU. Уверенное взаимодействие с Agile-командами, включая Data Architect, Data Engineer и Data Analyst. Развиты лидерские навыки управления командой и аналитические способности, необходимые для успешной реализации проектов AI-инфраструктуры.\",\n",
      "  \"skill_set\": [\n",
      "    \"PyTorch\",\n",
      "    \"NLP\",\n",
      "    \"LLM\",\n",
      "    \"LangChain\",\n",
      "    \"Prompt Engineering\",\n",
      "    \"RAG\",\n",
      "    \"Fine-tuning моделей\",\n",
      "    \"MLOps\",\n",
      "    \"Валидация моделей\",\n",
      "    \"Управление командой\",\n",
      "    \"Аналитические навыки\",\n",
      "    \"Коммуникабельность\"\n",
      "  ],\n",
      "  \"experience\": [\n",
      "    {\n",
      "      \"description\": \"Опыт работы более 3 лет в области машинного обучения с фокусом на развитие и продуктивное внедрение LLM-решений, управление командами и процессы MLOps. \\n\\n***ПРОЕКТ***: Telegram-бот для автоматизации поздравлений сотрудников с использованием NLP и LLM-технологий\\nСТЕК: Python, Telegram API, Pymorphy2, Yandex SpeechKit (Text-to-Speech)\\nЗАДАЧА: Автоматизация ручного процесса создания персонализированных голосовых поздравлений, ранее требовавшего значительных временных затрат и участия операторов.\\nРЕШЕНИЕ: Разработан Telegram-бот на Python, интегрированный с внутренними системами компании, обеспечивающий генерацию аудиопоздравлений с корректным лингвистическим анализом имён и выбором голоса. Проект акцентировал внимание на качестве NLP-моделей и глубокой интеграции в бизнес-процессы.\\nРЕЗУЛЬТАТ: Время создания поздравлений сократилось с нескольких часов до нескольких секунд; производительность выросла до 100 поздравлений в день; повышена точность корпоративной коммуникации с исключением человеческих ошибок.\",\n",
      "      \"position\": \"AI Engineer\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"***ПРОЕКТ***: Корпоративный интеллектуальный поиск и автоответчик на основе LLM с использованием LangChain и RAG\\nСТЕК: Python, NLTK, Hugging Face Transformers, LangChain, LangGraph, semantic_router, Ollama, vLLM, Chroma, Pinecone, Docker, NVIDIA GPU\\nЗАДАЧА: Разработка промышленной системы точного семантического роутинга и автоматизированного ответа на запросы сотрудников по внутренней документации, заменяющей менее точные методы поиска и ручную работу операторов.\\nРЕШЕНИЕ: Создан многоуровневый ансамбль локальных LLM (Llama 3, модели 7B и 70B) с использованием LangChain и semantic_router, а также внедрена архитектура RAG без применения классического векторного поиска. Произведена обработка исходных документов в структурированный JSON, автоматическое разделение запросов и голосующее решение для точного выбора ответов. Модели эмбеддингов адаптированы и дообучены на размеченной обратной связи; внедрена миграция с Chroma на Pinecone для оптимизации метрик. Проект развёрнут в Docker с поддержкой GPU NVIDIA. Исполнена полноценная организация валидационных процедур моделей и взаимодействие с Data Architect, Data Engineer, Data Analyst в рамках Agile-команды.\\nРЕЗУЛЬТАТ: Повышение точности маршрутизации на 40%, сокращение ошибок выбора файлов на 50%, успешная интеграция решения в 4 подразделениях с высокой масштабируемостью и возможностью тиражирования.\",\n",
      "      \"position\": \"AI Engineer\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"***ПРОЕКТ***: Чат-боты-кураторы на базе LLM для автоматизации проверки учебных заданий с промышленной эксплуатацией\\nСТЕК: Python, GPT-4, GPT-3.5, LangChain, Pinecone, Pymorphy2, методы prompt engineering (Chain of Thought, Tree of Thought), fine-tuning, API\\nЗАДАЧА: Автоматизация процесса проверки домашних заданий, занимавшего до 65% времени кураторов, что замедляло обратную связь.\\nРЕШЕНИЕ: Реализованы четыре чат-бота на Python с интеграцией LangChain и LLM, обеспечивающие эффективную проверку по различным дисциплинам. Гибридный поиск ответов через Pinecone и морфологический анализ запросов. Проведено дообучение GPT-3.5 на обширном корпусе, что улучшило качество и снизило стоимость запросов. Активно применялись современные технологии RAG и передовые методы prompt engineering, включая организацию процессов валидации моделей. Работа велась в рамках Agile, с тесным взаимодействием с Data Engineer и Data Analyst, а также управлением проектом.\\nРЕЗУЛЬТАТ: Значительное сокращение времени проверки, повышение качества обратной связи и экономия около 30% годовых затрат на ручную проверку, улучшение удовлетворённости пользователей за счёт стабильного и качественного сервиса.\",\n",
      "      \"position\": \"AI Engineer\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"***ПРОЕКТ***: Автоматизированный аудит телефонных звонков с применением LLM и MLOps\\nСТЕК: Python, GPT-4, LangChain, LlamaIndex, JSON, методы prompt engineering (Self-Reflection, Decomposition)\\nЗАДАЧА: Обеспечить точность и объективность анализа звонков операторов с клиентами, исключая человеческий фактор.\\nРЕШЕНИЕ: Создана система на GPT-4 с генерацией подробных отчётов в структурированном формате JSON, внедрён механизм само-анализа и корректировки результатов моделей. Благодаря MLOps практикам обеспечена поддержка и мониторинг качества инференса. Проект включал взаимодействие с инженерной командой для развёртывания и поддержки решения.\\nРЕЗУЛЬТАТ: Превышение качества аудита, ускорение процессов, повышение управляемости коммуникаций и прозрачности внутри компании.\",\n",
      "      \"position\": \"AI Engineer\"\n",
      "    },\n",
      "    {\n",
      "      \"description\": \"***ПРОЕКТ***: Разработка RAG-системы и валидация моделей для образовательного проекта астрологической школы\\nСТЕК: Python, LangChain, LlamaIndex, GPT-4, RAGAS, Pandas, Chroma, Pinecone, vLLM, PyMuPDF\\nЗАДАЧА: Создание высокоточного ответа на вопросы студентов по учебной документации с проверкой качества и достоверности ответов.\\nРЕШЕНИЕ: Построена RAG-система с комплексным семантическим индексированием и роутингом. Реализован пайплайн валидации с использованием RAGAS, обеспечивающий метрики качества (faithfulness, context relevancy, answer relevancy и др.). Проект интегрирован в CI для отслеживания деградаций. На основе данных подготовлен датасет с эталонными ответами и метаданными.\\nРАЗВИТИЕ: Проект развёрнут с использованием MLOps-подходов, включающих мониторинг и поддержку производительности модели. Результаты высоко оценены за снижение галлюцинаций и повышение релевантности.\\n\\nДополнительно: Опыт работы в роли контент-менеджера способствует развитым навыкам коммуникации и организации командной работы.\",\n",
      "      \"position\": \"AI Engineer\"\n",
      "    }\n",
      "  ],\n",
      "  \"professional_roles\": [\n",
      "    {\n",
      "      \"name\": \"Дата-сайентист\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Программист, разработчик\"\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Руководитель проектов\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Результат сохранен в файл: updated_resume_result.json\n"
     ]
    }
   ],
   "source": [
    "# Асинхронная функция для выполнения запроса\n",
    "async def run_resume_update():\n",
    "    print(\"\\n=== ЗАПУСК ФИНАЛЬНОГО РЕРАЙТА РЕЗЮМЕ ===\")\n",
    "    print(\"Отправляем запрос к LLM API...\")\n",
    "    \n",
    "    try:\n",
    "        # Вызываем метод update_resume для получения результата\n",
    "        result = await resume_updater.update_resume(parsed_resume_dict, gap_result)\n",
    "        \n",
    "        if result:\n",
    "            print(\"\\n✅ Резюме успешно обновлено!\")\n",
    "            \n",
    "            # # Выводим ключевые обновленные поля\n",
    "            # print(f\"\\nНовая должность: {result.title}\")\n",
    "            # print(\"\\nОбновленное описание навыков:\")\n",
    "            # print(result.skills)\n",
    "            \n",
    "            # print(\"\\nОбновленные ключевые навыки:\")\n",
    "            # for skill in result.skill_set:\n",
    "            #     print(f\"- {skill}\")\n",
    "            \n",
    "            # print(\"\\nОбновленный опыт работы:\")\n",
    "            # for i, exp in enumerate(result.experience, 1):\n",
    "            #     print(f\"\\nОпыт {i}:\")\n",
    "            #     print(f\"Должность: {exp.position}\")\n",
    "            #     print(f\"Описание: {exp.description}\")\n",
    "            \n",
    "            # Выводим полный JSON результата\n",
    "            print(\"\\n=== ПОЛНЫЙ JSON РЕЗУЛЬТАТА ===\")\n",
    "            print(json.dumps(result.model_dump(), ensure_ascii=False, indent=2))\n",
    "            \n",
    "            # Сохраняем результат в файл\n",
    "            result_path = Path(\"updated_resume_result.json\")\n",
    "            with open(result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(result.model_dump(), f, ensure_ascii=False, indent=2)\n",
    "            print(f\"\\nРезультат сохранен в файл: {result_path}\")\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            print(\"\\n❌ Ошибка: Не удалось получить результат от LLM\")\n",
    "            return None\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Ошибка при выполнении финального рерайта: {e}\")\n",
    "        return None\n",
    "\n",
    "# Запускаем асинхронную функцию\n",
    "result = await run_resume_update()  # Для Jupyter нужно использовать top-level await"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aab442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df5106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb348166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d23f6bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (semantic_venv)",
   "language": "python",
   "name": "semantic_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
