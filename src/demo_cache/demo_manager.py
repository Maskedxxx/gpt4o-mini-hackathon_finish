"""
Demo Manager –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏ LLM –≤ –¥–µ–º–æ-—Ä–µ–∂–∏–º–µ.
–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –±—ã—Å—Ç—Ä—É—é –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é —Ñ—É–Ω–∫—Ü–∏–π –±–µ–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –≤—ã–∑–æ–≤–æ–≤ OpenAI API.
"""
import os
import json
import logging
from pathlib import Path
from typing import Optional, Dict, Any
from src.utils.logging_config import get_logger

logger = get_logger(__name__)


class DemoManager:
    """–£–ø—Ä–∞–≤–ª—è–µ—Ç –¥–µ–º–æ-—Ä–µ–∂–∏–º–æ–º –∏ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –ø—É—Ç—è–º–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º –∫–µ—à–∞"""
        self.project_root = Path(__file__).parent.parent.parent
        self.demo_cache_dir = self.project_root / "demo_cache"
        
        # –ü—É—Ç–∏ –∫ –æ—Å–Ω–æ–≤–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        self.resume_profiles_dir = self.demo_cache_dir / "resume_profiles"
        self.vacancy_data_dir = self.demo_cache_dir / "vacancy_data"
        self.cached_responses_dir = self.demo_cache_dir / "cached_responses"
        self.generated_pdfs_dir = self.demo_cache_dir / "generated_pdfs"
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
        self._ensure_directories_exist()
    
    def _ensure_directories_exist(self) -> None:
        """–°–æ–∑–¥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç"""
        directories = [
            self.resume_profiles_dir,
            self.vacancy_data_dir,
            self.cached_responses_dir / "cover_letter",
            self.cached_responses_dir / "interview_checklist", 
            self.cached_responses_dir / "interview_simulation",
            self.generated_pdfs_dir / "cover_letter",
            self.generated_pdfs_dir / "interview_checklist",
            self.generated_pdfs_dir / "interview_simulation"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def is_demo_mode(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –¥–µ–º–æ-—Ä–µ–∂–∏–º–∞ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é DEMO_MODE=true
        
        Returns:
            bool: True –µ—Å–ª–∏ –¥–µ–º–æ-—Ä–µ–∂–∏–º –∞–∫—Ç–∏–≤–µ–Ω, False –∏–Ω–∞—á–µ
        """
        demo_mode = os.getenv("DEMO_MODE", "false").lower()
        is_active = demo_mode in ("true", "1", "yes", "on")
        
        if is_active:
            logger.info("üé≠ Demo mode is ACTIVE - using cached responses")
        else:
            logger.info("üåê Live mode is ACTIVE - making real OpenAI API calls")
            
        return is_active
    
    def save_response(self, service_type: str, profile_level: str, response_data: dict) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—Ç–≤–µ—Ç LLM –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π JSON —Ñ–∞–π–ª
        
        Args:
            service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞ ('cover_letter', 'interview_checklist', 'interview_simulation')  
            profile_level: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è ('junior', 'middle', 'senior')
            response_data: –î–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            
        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        if service_type not in ["cover_letter", "interview_checklist", "interview_simulation"]:
            raise ValueError(f"Invalid service_type: {service_type}")
            
        if profile_level not in ["junior", "middle", "senior"]:
            raise ValueError(f"Invalid profile_level: {profile_level}")
        
        file_path = self.cached_responses_dir / service_type / f"{profile_level}_response.json"
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(response_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ Saved cached response: {service_type}/{profile_level}_response.json")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save response for {service_type}/{profile_level}: {e}")
            raise
    
    def load_cached_response(self, service_type: str, profile_level: str) -> Optional[dict]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ –∫–ª—é—á—É
        
        Args:
            service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞
            profile_level: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è
            
        Returns:
            Optional[dict]: –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        if service_type not in ["cover_letter", "interview_checklist", "interview_simulation"]:
            logger.warning(f"‚ö†Ô∏è Invalid service_type: {service_type}")
            return None
            
        if profile_level not in ["junior", "middle", "senior"]:
            logger.warning(f"‚ö†Ô∏è Invalid profile_level: {profile_level}")
            return None
        
        file_path = self.cached_responses_dir / service_type / f"{profile_level}_response.json"
        
        if not file_path.exists():
            logger.warning(f"üìÇ Cached response not found: {file_path}")
            return None
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            logger.info(f"üì• Loaded cached response: {service_type}/{profile_level}_response.json")
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load cached response {service_type}/{profile_level}: {e}")
            return None
    
    def get_pdf_path(self, service_type: str, profile_level: str) -> Optional[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–º—É PDF —Ñ–∞–π–ª—É
        
        Args:
            service_type: –¢–∏–ø —Å–µ—Ä–≤–∏—Å–∞
            profile_level: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è
            
        Returns:
            Optional[str]: –ü—É—Ç—å –∫ PDF —Ñ–∞–π–ª—É –∏–ª–∏ None –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
        """
        if service_type not in ["cover_letter", "interview_checklist", "interview_simulation"]:
            logger.warning(f"‚ö†Ô∏è Invalid service_type: {service_type}")
            return None
            
        if profile_level not in ["junior", "middle", "senior"]:
            logger.warning(f"‚ö†Ô∏è Invalid profile_level: {profile_level}")
            return None
        
        file_path = self.generated_pdfs_dir / service_type / f"{profile_level}_{service_type}.pdf"
        
        if not file_path.exists():
            logger.warning(f"üìÇ Pre-generated PDF not found: {file_path}")
            return None
        
        logger.info(f"üìÑ Found pre-generated PDF: {service_type}/{profile_level}_{service_type}.pdf")
        return str(file_path)
    
    def detect_profile_level(self, resume_data: dict) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è (junior/middle/senior) –ø–æ –¥–∞–Ω–Ω—ã–º —Ä–µ–∑—é–º–µ
        
        Args:
            resume_data: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ —Ä–µ–∑—é–º–µ
            
        Returns:
            str: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è ('junior', 'middle', 'senior')
        """
        if not isinstance(resume_data, dict):
            logger.warning("‚ö†Ô∏è resume_data is not a dict, defaulting to junior")
            return "junior"
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤–µ—Å—å –æ–±—ä–µ–∫—Ç —Ä–µ–∑—é–º–µ –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        resume_text = json.dumps(resume_data, ensure_ascii=False).lower()
        
        # –ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —É—Ä–æ–≤–Ω—è
        senior_indicators = [
            "senior", "lead", "architect", "team lead", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å", "–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä",
            "principal", "staff", "–≥–ª–∞–≤–Ω—ã–π", "–≤–µ–¥—É—â–∏–π", "—Ç–∏–º–ª–∏–¥", "—Ç–µ—Ö–ª–∏–¥"
        ]
        
        middle_indicators = [
            "middle", "–º–∏–¥–ª", "–æ–ø—ã—Ç–Ω—ã–π", "3+ –≥–æ–¥–∞", "4+ –≥–æ–¥–∞", "5+ –ª–µ—Ç", 
            "—Ç—Ä–∏ –≥–æ–¥–∞", "—á–µ—Ç—ã—Ä–µ –≥–æ–¥–∞", "–ø—è—Ç—å –ª–µ—Ç", "—Å—Ä–µ–¥–Ω–∏–π", "intermediate"
        ]
        
        junior_indicators = [
            "junior", "–¥–∂—É–Ω–∏–æ—Ä", "–Ω–∞—á–∏–Ω–∞—é—â–∏–π", "—Å—Ç–∞–∂–µ—Ä", "–±–µ–∑ –æ–ø—ã—Ç–∞", "1 –≥–æ–¥",
            "–≥–æ–¥ –æ–ø—ã—Ç–∞", "junior developer", "entry level", "trainee"
        ]
        
        # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
        senior_score = sum(1 for indicator in senior_indicators if indicator in resume_text)
        middle_score = sum(1 for indicator in middle_indicators if indicator in resume_text)
        junior_score = sum(1 for indicator in junior_indicators if indicator in resume_text)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã
        total_experience = resume_data.get('total_experience', 0)
        if isinstance(total_experience, dict):
            months = total_experience.get('months', 0)
        elif isinstance(total_experience, (int, float)):
            months = total_experience
        else:
            months = 0
        
        # –û–ø—ã—Ç –≤ –≥–æ–¥–∞—Ö –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–∏
        years_experience = months / 12 if months > 0 else 0
        
        # –ë–æ–Ω—É—Å—ã –∫ —Å–∫–æ—Ä–∞–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–ø—ã—Ç–∞
        if years_experience >= 5:
            senior_score += 2
        elif years_experience >= 2:
            middle_score += 2
        elif years_experience < 2:
            junior_score += 1
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É —Å–∫–æ—Ä—É
        if senior_score >= max(middle_score, junior_score):
            detected_level = "senior"
        elif middle_score >= junior_score:
            detected_level = "middle"  
        else:
            detected_level = "junior"
        
        logger.info(f"üéØ Profile level detected: {detected_level} "
                   f"(scores: senior={senior_score}, middle={middle_score}, junior={junior_score}, "
                   f"experience={years_experience:.1f} years)")
        
        return detected_level
    
    def save_resume_profile(self, profile_level: str, resume_data: dict) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ—Ñ–∏–ª—å —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ
        
        Args:
            profile_level: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª—è
            resume_data: –î–∞–Ω–Ω—ã–µ —Ä–µ–∑—é–º–µ
            
        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        if profile_level not in ["junior", "middle", "senior"]:
            raise ValueError(f"Invalid profile_level: {profile_level}")
        
        file_path = self.resume_profiles_dir / f"{profile_level}_profile.json"
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(resume_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ Saved resume profile: {profile_level}_profile.json")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save resume profile {profile_level}: {e}")
            raise
    
    def save_vacancy_data(self, vacancy_data: dict) -> str:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
        
        Args:
            vacancy_data: –î–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
            
        Returns:
            str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        file_path = self.vacancy_data_dir / "target_vacancy.json"
        
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(vacancy_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"üíæ Saved vacancy data: target_vacancy.json")
            return str(file_path)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to save vacancy data: {e}")
            raise
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è
        
        Returns:
            Dict: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –∏ PDF —Ñ–∞–π–ª–æ–≤
        """
        stats = {
            "demo_mode_active": self.is_demo_mode(),
            "cached_responses": {},
            "generated_pdfs": {},
            "total_cached_responses": 0,
            "total_generated_pdfs": 0
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
        for service_type in ["cover_letter", "interview_checklist", "interview_simulation"]:
            service_responses = 0
            service_pdfs = 0
            
            for profile_level in ["junior", "middle", "senior"]:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤
                response_file = self.cached_responses_dir / service_type / f"{profile_level}_response.json"
                if response_file.exists():
                    service_responses += 1
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ PDF —Ñ–∞–π–ª–æ–≤
                pdf_file = self.generated_pdfs_dir / service_type / f"{profile_level}_{service_type}.pdf"
                if pdf_file.exists():
                    service_pdfs += 1
            
            stats["cached_responses"][service_type] = service_responses
            stats["generated_pdfs"][service_type] = service_pdfs
            stats["total_cached_responses"] += service_responses
            stats["total_generated_pdfs"] += service_pdfs
        
        return stats